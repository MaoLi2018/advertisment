{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "sys.path.append('tools/tensorflow-DeepFM-master/')\n",
    "\n",
    "import config\n",
    "import DataReader\n",
    "from DeepFM import DeepFM\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.metrics import log_loss,roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#0099ff size=5 face=\"黑体\">固定函数</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hour_ouput(value):\n",
    "    return time.localtime(value).tm_hour\n",
    "\n",
    "def day_ouput(value):\n",
    "    return time.localtime(value).tm_mday\n",
    "\n",
    "\n",
    "\n",
    "def process(df):\n",
    "    cols = [c for c in df.columns if c not in config.KEYS]\n",
    "    for i in range(1,3):\n",
    "        df['item_category_list_bin_%d'%i] = df['item_category_list'].apply(lambda x: x.split(';')[i] if len(x.split(';'))>i else -1)\n",
    "        \n",
    "        #df['item_property_list_bin_%d'%i] = df['item_property_list'].apply(lambda x: x.split(';')[i] if len(x.split(';'))>i else -1)\n",
    "        #df['item_property_list_bin_%d'%i] = df['item_property_list'].apply(lambda x: x.split(';')[i] if len(x.split(';'))>i else -1)\n",
    "    df['item_property_list'] = dfTrain['item_property_list'].apply(lambda x:';'.join(sorted(set(x.split(';')))))\n",
    "    df[\"missing_feat\"] = np.sum((df[cols] == -1).values, axis=1)\n",
    "    df['context_timestamp_hour'] = df['context_timestamp'].map(hour_ouput)\n",
    "    df['context_timestamp_day'] = df['context_timestamp'].map(day_ouput)\n",
    "    return df\n",
    "\n",
    "#def string_process(dfTrain,dfTest):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#0099ff size=5 face=\"黑体\">读取数据</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TrainX = dfTrain[featInput].values\\nTestX = dfTest[featInput].values\\nTrainy = dfTrain[config.LABEL].values'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain = pd.read_table(config.TRAIN_FILE,sep=' ')\n",
    "dfTest = pd.read_table(config.TEST_FILE,sep=' ')\n",
    "\n",
    "dfTrain = process(dfTrain)\n",
    "dfTest = process(dfTest)\n",
    "\n",
    "\n",
    "featInput = [c for c in dfTrain.columns if c not in config.KEYS]\n",
    "featInput = [c for c in featInput if (not c in config.IGNORE_COLS)]\n",
    "\n",
    "'''TrainX = dfTrain[featInput].values\n",
    "TestX = dfTest[featInput].values\n",
    "Trainy = dfTrain[config.LABEL].values'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#0099ff size=5 face=\"黑体\">生成稀疏特征</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = DataReader.FeatureDictionary(dfTrain=dfTrain, dfTest=dfTest,\n",
    "                           numeric_cols=config.NUMERIC_COLS,\n",
    "                           ignore_cols=config.IGNORE_COLS,\n",
    "                           active_bound=1)\n",
    "data_parser = DataReader.DataParser(feat_dict=fd)\n",
    "Xi_train, Xv_train, y_train = data_parser.parse(df=dfTrain, has_label=True)\n",
    "#Xi_test, Xv_test, ids_test = data_parser.parse(df=dfTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#0099ff size=5 face=\"黑体\">设置模型参数</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22405\n"
     ]
    }
   ],
   "source": [
    "dfm_params = {\n",
    "    \"use_fm\": True,\n",
    "    \"use_deep\": True,\n",
    "    \"embedding_size\": 8,\n",
    "    \"dropout_fm\": [1.0, 1.0],\n",
    "    \"deep_layers\": [32, 32],\n",
    "    \"dropout_deep\": [0.5, 0.5, 0.5],\n",
    "    \"deep_layers_activation\": tf.nn.relu,\n",
    "    \"epoch\": 20,\n",
    "    \"batch_size\": 2048,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer_type\": \"adam\",\n",
    "    \"batch_norm\": 1,\n",
    "    \"batch_norm_decay\": 0.995,\n",
    "    \"l2_reg\": 0.01,\n",
    "    \"verbose\": True,\n",
    "    \"eval_metric\": log_loss,\n",
    "    \"random_seed\": config.RANDOM_SEED\n",
    "}\n",
    "dfm_params[\"feature_size\"] = fd.feat_dim\n",
    "dfm_params[\"field_size\"] = len(Xi_train[0])\n",
    "print(dfm_params[\"feature_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "appendList = list(set(train_idx)&set(dfTrain.loc[dfTrain['is_trade']==1].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24150"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(appendList*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'Int64Index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e2550460cea7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfTrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdfTrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'context_timestamp_day'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_idx_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfTrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdfTrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'is_trade'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2137\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2138\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2144\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2145\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2146\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2148\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1838\u001b[0m         \u001b[1;34m\"\"\"Return the cached item, item represents a label indexer.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1839\u001b[0m         \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_item_cache\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1840\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1841\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1719\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1720\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1721\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"unhashable type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1723\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'Int64Index'"
     ]
    }
   ],
   "source": [
    "train_idx = dfTrain.loc[dfTrain['context_timestamp_day']<24].index\n",
    "train_idx_tmp = dfTrain.loc[dfTrain[train_idx,'is_trade']==1].index\n",
    "train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#params: 208942\n",
      "[1] train-result=0.2517, valid-result=0.2267 [20.5 s]\n",
      "[2] train-result=0.1870, valid-result=0.1480 [21.8 s]\n",
      "[3] train-result=0.1591, valid-result=0.1123 [21.7 s]\n",
      "[4] train-result=0.1485, valid-result=0.0979 [20.5 s]\n",
      "[5] train-result=0.1446, valid-result=0.0941 [21.1 s]\n",
      "[6] train-result=0.1407, valid-result=0.0957 [20.4 s]\n",
      "[7] train-result=0.1403, valid-result=0.0935 [21.0 s]\n",
      "[8] train-result=0.1395, valid-result=0.0940 [21.2 s]\n",
      "[9] train-result=0.1397, valid-result=0.0915 [20.6 s]\n",
      "[10] train-result=0.1395, valid-result=0.0929 [21.3 s]\n",
      "[11] train-result=0.1393, valid-result=0.0939 [25.1 s]\n",
      "[12] train-result=0.1391, valid-result=0.0935 [24.5 s]\n",
      "[13] train-result=0.1395, valid-result=0.0924 [24.9 s]\n",
      "[14] train-result=0.1388, valid-result=0.0922 [26.0 s]\n",
      "[15] train-result=0.1383, valid-result=0.0936 [24.7 s]\n",
      "[16] train-result=0.1386, valid-result=0.0932 [25.3 s]\n",
      "[17] train-result=0.1384, valid-result=0.0927 [24.2 s]\n",
      "[18] train-result=0.1378, valid-result=0.0950 [27.3 s]\n",
      "[19] train-result=0.1378, valid-result=0.0958 [26.0 s]\n",
      "[20] train-result=0.1379, valid-result=0.0943 [25.1 s]\n"
     ]
    }
   ],
   "source": [
    "###根据日期拆分训练集\n",
    "train_idx = dfTrain.loc[dfTrain['context_timestamp_day']<24].index\n",
    "valid_idx = dfTrain.loc[dfTrain['context_timestamp_day']==24].index\n",
    "\n",
    "train_idx = list(train_idx)+appendList\n",
    "\n",
    "_get = lambda x,l:[x[i] for i in l]\n",
    "Xi_train_, Xv_train_, y_train_ = _get(Xi_train, train_idx), _get(Xv_train, train_idx), _get(y_train, train_idx)\n",
    "Xi_valid_, Xv_valid_, y_valid_ = _get(Xi_train, valid_idx), _get(Xv_train, valid_idx), _get(y_train, valid_idx)\n",
    "\n",
    "dfm = DeepFM(**dfm_params)\n",
    "dfm.fit(Xi_train_, Xv_train_, y_train_, Xi_valid_, Xv_valid_, y_valid_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_valid_ = dfm.predict( Xi_valid_, Xv_valid_)\n",
    "print(log_loss(y_valid_, result_valid_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'target':y_valid_,'score':result_valid_})\n",
    "df['score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.sort_values('score',ascending=False,inplace=True)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:20,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_meta = np.zeros((dfTest.shape[0], 1), dtype=float)\n",
    "y_test_meta[:,0] += dfm.predict(Xi_test, Xv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_meta = np.zeros((dfTest.shape[0], 1), dtype=float)\n",
    "y_test_meta[:,0] += dfm.predict(Xi_test, Xv_test)\n",
    "y_test_meta[:,0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folds = list(KFold(n_splits=config.NUM_SPLITS,shuffle=True,random_state=config.RANDOM_SEED).split(dfTrain.values))\n",
    "_get = lambda x,l:[x[i] for i in l]\n",
    "\n",
    "y_test_meta = np.zeros((dfTest.shape[0], 1), dtype=float)\n",
    "\n",
    "for i,(train_idx, valid_idx) in enumerate(folds):\n",
    "    Xi_train_, Xv_train_, y_train_ = _get(Xi_train, train_idx), _get(Xv_train, train_idx), _get(y_train, train_idx)\n",
    "    Xi_valid_, Xv_valid_, y_valid_ = _get(Xi_train, valid_idx), _get(Xv_train, valid_idx), _get(y_train, valid_idx)\n",
    "\n",
    "    dfm = DeepFM(**dfm_params)\n",
    "    dfm.fit(Xi_train_, Xv_train_, y_train_, Xi_valid_, Xv_valid_, y_valid_)\n",
    "    \n",
    "    y_test_meta[:,0] += dfm.predict(Xi_test, Xv_test)\n",
    "    \n",
    "y_test_meta /= float(len(folds))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'instance_id':ids_test,'predicted_score':y_test_meta[:,0]})\n",
    "submit.to_csv('../../Submission/advertisement/FM_deep_0322.txt', sep=\" \", index=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit['predicted_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.log(0.9058)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2.15/18371\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

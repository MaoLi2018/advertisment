{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import config\n",
    "import re\n",
    "from numba import jit\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.metrics import log_loss,roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder,StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from itertools import chain, combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cosine(vec1, vec2):\n",
    "    vec1=Counter(vec1)\n",
    "    vec2=Counter(vec2)\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "            \n",
    "def timestamp_datetime(value):\n",
    "    return time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(value))\n",
    "\n",
    "def time_feat(df,featList,featName):\n",
    "    df[featName] = df.groupby(featList)['context_timestamp'].rank(method='first')   \n",
    "    return df\n",
    "\n",
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    return list(chain.from_iterable(combinations(s, r) for r in range(len(s)+1)))\n",
    "\n",
    "def ks_metric(true,score):\n",
    "    fpr, tpr, thresholds = roc_curve(true,score)\n",
    "    ks = max(tpr-fpr)\n",
    "    return ks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def process(df):\n",
    "    df['time'] = df.context_timestamp.apply(timestamp_datetime)\n",
    "    df['day'] = df.time.apply(lambda x: int(x[8:10]))\n",
    "    df['hour'] = df.time.apply(lambda x: int(x[11:13]))\n",
    "    '''for lst in timeFeatList:\n",
    "        df = time_feat(df,lst,'_'.join(lst))'''\n",
    "    df['item_property_list'] = df['item_property_list'].apply(lambda x:';'.join(sorted(set(str(x).split(';')))))\n",
    "    df['predict_category_property'] = df['predict_category_property'].apply(lambda x:';'.join(sorted(set(str(x).split(';')))))\n",
    "    df['len_item_property_list'] = df['item_property_list'].apply(lambda x: len(str(x).split(';')))\n",
    "    df['len_predict_category_property'] = df['predict_category_property'].apply(lambda x: len(str(x).split(';')))\n",
    "    lbl = LabelEncoder()\n",
    "    for i in range(1,3):\n",
    "        df['item_category_list_bin%d'%i] = lbl.fit_transform(df['item_category_list'].apply(lambda x: x.split(';')[i] if len(x.split(';'))>i else ''))\n",
    "    for i in range(10):\n",
    "        df['predict_category_property%d'%i] = lbl.fit_transform(df['predict_category_property'].apply(lambda x: x.split(';')[i] if len(x.split(';'))>i else ''))\n",
    "    \n",
    "    #df[\"missing_feat\"] = np.sum((df == -1).values, axis=1)\n",
    "    return df\n",
    "\n",
    "def labelencoder(df):\n",
    "    lbl = LabelEncoder()\n",
    "    for var in ['user_id','item_id','shop_id','item_brand_id','item_city_id']:\n",
    "        df[var] = lbl.fit_transform(df[var])\n",
    "    return df\n",
    "        \n",
    "\n",
    "def text_cosine(df):\n",
    "    df['tmp_cate'] = df['item_category_list'].apply(lambda x: x.split(';')[2] if len(x.split(';'))>2 else x.split(';')[1])\n",
    "    df['cate_predict_chk']=list(map(lambda x,y: 1 if x in y else 0 , df['tmp_cate'],df['predict_category_property']))\n",
    "    del df['tmp_cate']\n",
    "    \n",
    "    df['tmp_set_predict_property'] =df['predict_category_property'].apply(lambda x: set(re.split('[:;]',x)[1::2]))\n",
    "    df['tmp_set_item_property_list'] =df['item_property_list'].apply(lambda x: set(re.split('[;]',x)))\n",
    "    df['property_join_cnt'] = df[['tmp_set_predict_property','tmp_set_item_property_list']].apply(lambda x: len(x[0]&x[1])*1.0/len(x[0]|x[1]),axis=1)\n",
    "    df['property_gap1_cnt'] = df[['tmp_set_predict_property','tmp_set_item_property_list']].apply(lambda x: len(x[0]-x[1])*1.0/len(x[0]|x[1]),axis=1)\n",
    "    df['property_gap2_cnt'] = df[['tmp_set_predict_property','tmp_set_item_property_list']].apply(lambda x: len(x[1]-x[0])*1.0/len(x[0]|x[1]),axis=1)\n",
    "    del df['tmp_set_predict_property']\n",
    "    del df['tmp_set_item_property_list']\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    \n",
    "    \n",
    "def same_day_trick(df,key_var=[]):\n",
    "    if not isinstance(key_var,list):\n",
    "        key_var = [key_var]\n",
    "    nameBase = '_'.join(key_var)\n",
    "    ###当天前后的数据情况\n",
    "    df[nameBase+'_before_exist'] = ((df.groupby(key_var+['day'])['context_timestamp'].rank(method='min') - 1) > 0).astype(int)\n",
    "    df[nameBase+'_after_exist'] = ((df.groupby(key_var+['day'])['context_timestamp'].rank(method='min',ascending=False)- 1) > 0).astype(int)\n",
    "    df[nameBase+'_sametime_exist'] = ((df.groupby(key_var+['day'])['context_timestamp'].rank(method='max') - df.groupby(key_var+['day'])['context_timestamp'].rank(method='min')) > 0).astype(int)\n",
    "    #df = df.merge(df.groupby(key_var+['day'],as_index=False)['context_timestamp'].agg({nameBase+'_day_cnt':'count'}),'inner',key_var+['day'])\n",
    "    return df    \n",
    "\n",
    "def focus_one_record(df,key_var=[],time_diff=False):\n",
    "    if not isinstance(key_var,list):\n",
    "        key_var = [key_var]\n",
    "    nameBase = '_'.join(key_var)\n",
    "    ###当天前后的数据情况\n",
    "    df[nameBase+'_before_cnt'] = df.groupby(key_var+['day'])['context_timestamp'].rank(method='min') - 1\n",
    "    df[nameBase+'_after_cnt'] = df.groupby(key_var+['day'])['context_timestamp'].rank(method='min',ascending=False)- 1\n",
    "    df[nameBase+'_sametime_cnt'] = df.groupby(key_var+['day'])['context_timestamp'].rank(method='max') - df.groupby(key_var+['day'])['context_timestamp'].rank(method='min')+1\n",
    "    df = df.merge(df.groupby(key_var+['day'],as_index=False)['context_timestamp'].agg({nameBase+'_day_cnt':'count'}),'inner',key_var+['day'])\n",
    "    for feat in ['_before_cnt','_after_cnt','_sametime_cnt']:\n",
    "        df[nameBase+feat+'_ratio'] = df[nameBase+feat]*1.0/df[nameBase+'_day_cnt']\n",
    "                \n",
    "    ###前一天购买/浏览的数量\n",
    "    '''dfTmp =  df.groupby(key_var+['day'],as_index=False)['is_trade'].agg({nameBase+'_preday_trade_cnt':'sum',nameBase+'_preday_cnt':'count'})\n",
    "    dfTmp['day'] = dfTmp['day']+1\n",
    "    df = df.merge(dfTmp,'left',key_var+['day'])\n",
    "    df[nameBase+'_preday_trade_ratio'] = df[nameBase+'_preday_trade_cnt']*1.0/df[nameBase+'_preday_cnt']\n",
    "    for feat in ['_preday_trade_cnt','_preday_cnt','_preday_trade_ratio']:\n",
    "        df[nameBase+feat].fillna(0,inplace=True)'''\n",
    "        \n",
    "    if time_diff:\n",
    "        ###广告展示上下间隔\n",
    "        dfTmp = df[[nameBase+'_before_cnt',nameBase+'_after_cnt',nameBase+'_sametime_cnt','time']+key_var+['day']]\n",
    "        dfTmp.rename(columns={'time':'new_time'},inplace=True)\n",
    "        dfTmp['next_record'] = dfTmp[nameBase+'_before_cnt'] + dfTmp[nameBase+'_sametime_cnt'] + 1\n",
    "        dfTmp['last_record'] = dfTmp[nameBase+'_after_cnt'] + dfTmp[nameBase+'_sametime_cnt'] + 1\n",
    "        df = df.merge(dfTmp[key_var+['day','next_record','new_time']],'left',left_on = key_var+['day',nameBase+'_before_cnt'],right_on = key_var+['day','next_record'])\n",
    "        df[nameBase + '_next_time_dur'] = (pd.to_datetime(df['time'])-pd.to_datetime(df['new_time'])).dt.seconds\n",
    "        df[nameBase + '_next_time_dur'].fillna(999999,inplace=True)\n",
    "        df.loc[df[nameBase+'_sametime_cnt']>1,nameBase + '_next_time_dur'] = 0\n",
    "        del df['new_time']\n",
    "        del df['next_record']\n",
    "\n",
    "        df = df.merge(dfTmp[key_var+['day','last_record','new_time']],'left',left_on = key_var+['day',nameBase+'_after_cnt'],right_on = key_var+['day','last_record'])\n",
    "        df[nameBase + '_last_time_dur'] = (pd.to_datetime(df['new_time'])-pd.to_datetime(df['time'])).dt.seconds\n",
    "        df[nameBase + '_last_time_dur'].fillna(999999,inplace=True)\n",
    "        df.loc[df[nameBase+'_sametime_cnt']>1,nameBase + '_last_time_dur'] = 0\n",
    "        del df['new_time']\n",
    "        del df['last_record']\n",
    "    for feat in ['_before_cnt','_after_cnt','_sametime_cnt']:\n",
    "        del df[nameBase+feat]\n",
    "    return df    \n",
    "    \n",
    "\n",
    "def _offline_feat(df,key_var='user_id',stat_var=[],part_var=[],mean_var=[],train_feat_col=None):\n",
    "    if not isinstance(key_var,list):\n",
    "        key_var = [key_var]\n",
    "    left_key = key_var.copy()\n",
    "    base_name = '~'.join(key_var)\n",
    "    if train_feat_col:\n",
    "        key_var.append(train_feat_col[1])\n",
    "        left_key.append(train_feat_col[0])\n",
    "        \n",
    "    \n",
    "    df = df.merge(df.groupby(key_var,as_index=False)['instance_id'].agg({base_name+'_cnt':'count'}).rename(columns={train_feat_col[1]:train_feat_col[0]}),'left',left_key)\n",
    "    df = df.merge(df.groupby(key_var,as_index=False)['is_trade'].agg({base_name+'_trade_cnt':'sum',base_name+'_trade_ratio':'mean'}).rename(columns={train_feat_col[1]:train_feat_col[0]}),'left',left_key)\n",
    "    df[base_name+'_notrade_cnt'] = df[base_name+'_cnt']-df[base_name+'_trade_cnt']\n",
    "    dfTmp = df.loc[df['is_trade']==1]\n",
    "    for stat in stat_var:\n",
    "        df = df.merge(df.groupby(key_var,as_index=False)[stat].agg({base_name+'_'+stat+'_min':'min',base_name+'_'+stat+'_max':'max'}).rename(columns={train_feat_col[1]:train_feat_col[0]}),'left',left_key)    \n",
    "    for part in part_var:\n",
    "        df = df.merge(df.groupby(key_var,as_index=False)[part].agg({base_name+'_'+part+'_cnt':'nunique'}).rename(columns={train_feat_col[1]:train_feat_col[0]}),'left',left_key)\n",
    "        df = df.merge(dfTmp.groupby(key_var,as_index=False)[part].agg({base_name+'_'+part+'_trade_cnt':'nunique'}).rename(columns={train_feat_col[1]:train_feat_col[0]}),'left',left_key)\n",
    "        df[base_name+'_'+part+'_trade_cnt'].fillna(0,inplace=True)\n",
    "        df[base_name+'_'+part+'_trade_ratio'] = 1.0*df[base_name+'_'+part+'_trade_cnt']/df[base_name+'_'+part+'_cnt']\n",
    "    for var in mean_var:\n",
    "        df = df.merge(df.groupby(key_var+[var],as_index=False)['is_trade'].sum().groupby(key_var,as_index=False)['is_trade'].agg({base_name+'_'+var+'_avg_trade':'mean'}).rename(columns={train_feat_col[1]:train_feat_col[0]}),'left',left_key)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def map_col(df,drop=False):\n",
    "    map_dict = {\n",
    "        'item_price_level':[4,5,6,7,8,9],\n",
    "        'item_sales_level':[4,6,9,10,11,12,13,14,16],\n",
    "        'item_pv_level':[6,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "        'user_age_level':[1001,1002,1003,1004,1005],\n",
    "        'context_page_id':[4001,4002,4004,4006,4008,4010,4013,4016,4018],\n",
    "        'shop_review_num_level':[5,9,14,15,16,17,18,20,21],\n",
    "        'hour':[6,9,12,17,20],\n",
    "        'user_occupation_id':{-1:2003},\n",
    "        'user_star_level':{-1:3000}\n",
    "    }\n",
    "    for key,value in map_dict.items():\n",
    "        if isinstance(value,list):\n",
    "            df[key+'_mapped'] = 0\n",
    "            for i in range(len(value)):\n",
    "                df.loc[df[key]>value[i],key+'_mapped'] = i+1\n",
    "        else:\n",
    "            '''df[key+'_mapped'] = df[key]\n",
    "            for key_sub,value_sub in value.items():\n",
    "                df.loc[df[key]==key_sub,key+'_mapped'] = value_sub'''\n",
    "            df[key+'_mapped'] = df[key].apply(lambda x:value.get(x,x))\n",
    "        if drop:\n",
    "            df[key] = df[key+'_mapped']\n",
    "            del df[key+'_mapped']\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def cross_feat_plus(df,base_list,order=2):\n",
    "    if order<2:\n",
    "        return df\n",
    "    subset = powerset(base_list)\n",
    "    subset = [i for i in subset if len(i)==order]\n",
    "    for sub in subset:\n",
    "        sub = list(sub)\n",
    "        baseName = '~'.join(sub)+'_plus'\n",
    "        df[baseName] = df[sub].sum(axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def interaction_ratio(df,base_list=[],cal_list=[],rank_list = []):\n",
    "    for base_var in base_list:\n",
    "        if not isinstance(base_var,list):\n",
    "            base_var = [base_var]\n",
    "        if not '_'.join(base_var)+'_cnt' in df.columns:\n",
    "            df = df.merge(df.groupby(base_var,as_index=False)['instance_id'].agg({'_'.join(base_var)+'_cnt':'count'}),'left',base_var)\n",
    "        print('ratio part')\n",
    "        for cal_var in cal_list:\n",
    "            if not isinstance(cal_var,list):\n",
    "                cal_var = [cal_var]\n",
    "            if cal_var==base_var or base_var==['cnt_rec']:\n",
    "                continue\n",
    "            nameBase = '_'.join(base_var)+'~'+'_'.join(cal_var)\n",
    "            print(nameBase)\n",
    "            df = df.merge(df.groupby(base_var+cal_var,as_index=False)['instance_id'].agg({nameBase+'_cnt':'count'}),'left',base_var+cal_var)\n",
    "            df[nameBase+'_ratio'] = df[nameBase+'_cnt']*1.0/df['_'.join(base_var)+'_cnt']\n",
    "            del df[nameBase+'_cnt']\n",
    "        \n",
    "        print('rank part')\n",
    "        for rank_var in rank_list:\n",
    "            if not isinstance(rank_var,list):\n",
    "                rank_var = [rank_var]\n",
    "            if rank_var==base_var:\n",
    "                continue\n",
    "            nameBase = '_'.join(base_var)+'~'+'_'.join(rank_var)\n",
    "            print(nameBase)\n",
    "            df[nameBase+'_rank'] = dfAll.groupby(base_var)[rank_var].rank(method='min')\n",
    "            df[nameBase+'_rank_ratio'] = df[nameBase+'_rank']*1.0/df['_'.join(base_var)+'_cnt']\n",
    "            del df[nameBase+'_rank']\n",
    "        del df['_'.join(base_var)+'_cnt']\n",
    "    return df\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#0099ff size=5 face=\"黑体\">读取数据</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(520999, 45)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(520999, 49)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain = pd.read_table(config.TRAIN_FILE,sep=' ')\n",
    "dfTrain.drop_duplicates(inplace=True)\n",
    "dfTrain.reset_index(inplace=True,drop =True)\n",
    "dfTest = pd.read_table(config.TEST_FILE,sep=' ')\n",
    "\n",
    "dfTrain = process(dfTrain)\n",
    "dfTest = process(dfTest)\n",
    "\n",
    "dfAll = pd.concat([dfTrain,dfTest],axis=0)\n",
    "dfAll.reset_index(inplace=True,drop=True)\n",
    "trainNum = dfTrain.shape[0]\n",
    "dfAll['cnt_rec'] = 1\n",
    "print(dfAll.shape)\n",
    "\n",
    "dfAll = labelencoder(dfAll)\n",
    "dfAll = text_cosine(dfAll)\n",
    "dfAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#0099ff size=5 face=\"黑体\">特征工程</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(520999, 49)\n"
     ]
    }
   ],
   "source": [
    "###单特征map\n",
    "dfAll = map_col(dfAll,True)\n",
    "print(dfAll.shape)\n",
    "featBase = [i for i in dfAll.columns.tolist() if not i in config.IGNORE_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(520999, 177)\n"
     ]
    }
   ],
   "source": [
    "###线下特征集合\n",
    "dfAll['feat_set'] = dfAll['day'] + 1\n",
    "keyList = ['user_id','shop_id','item_id','hour']\n",
    "partList = [\n",
    "    ['item_id','shop_id'],\n",
    "    ['user_id','item_id'],\n",
    "    ['user_id','shop_id'],\n",
    "    ['user_id','item_id','shop_id']\n",
    "]\n",
    "meanList = [\n",
    "    ['shop_id'],\n",
    "    ['item_id'],\n",
    "    [],\n",
    "    ['user_id','shop_id','item_id']\n",
    "]\n",
    "for i in range(len(keyList)):\n",
    "    keyVar = keyList[i]\n",
    "    partVar = partList[i]\n",
    "    meanVar = meanList[i]\n",
    "    statVar = []\n",
    "    if isinstance(keyVar,str):\n",
    "        for key,value in config.STAT_DICT.items():\n",
    "            if key==keyVar:\n",
    "                continue\n",
    "            statVar += value\n",
    "    dfAll = _offline_feat(dfAll,keyVar,statVar,partVar,meanVar,['day','feat_set'])\n",
    "del dfAll['feat_set']\n",
    "print(dfAll.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(520999, 342)\n"
     ]
    }
   ],
   "source": [
    "###连续型变量交叉特征\n",
    "conList = [\n",
    "    'user_gender_id','user_age_level', 'user_star_level',\n",
    "    'item_price_level', 'item_sales_level','item_collected_level', 'item_pv_level',\n",
    "    'context_page_id',\n",
    "    'shop_review_num_level','shop_star_level'\n",
    "]\n",
    "dfAll = cross_feat_plus(dfAll,conList,order=2)\n",
    "dfAll = cross_feat_plus(dfAll,conList,order=3)\n",
    "print(dfAll.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(520999, 345)\n"
     ]
    }
   ],
   "source": [
    "###当天信息的trick\n",
    "keyList = ['user_id']\n",
    "#,'shop_id','item_id','item_city_id','item_brand_id'\n",
    "for keyVar in keyList:\n",
    "    '''timeDiff = False if keyVar=='user_id' else True\n",
    "    dfAll = focus_one_record(dfAll,keyVar,timeDiff)'''\n",
    "    dfAll = same_day_trick(dfAll,keyVar)\n",
    "print(dfAll.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###两两类别变量的比例/rank 顺序\n",
    "'''baseList = [\n",
    "    'cnt_rec',\n",
    "    'user_id','user_gender_id', 'user_occupation_id','user_age_level', 'user_star_level',\n",
    "    'item_id', 'item_brand_id', 'item_city_id', 'item_price_level', 'item_sales_level','item_collected_level', 'item_pv_level',\n",
    "    'item_category_list_bin1','item_category_list_bin2',\n",
    "    'shop_id', 'shop_review_num_level','shop_star_level'\n",
    "    \n",
    "]\n",
    "\n",
    "calList = [\n",
    "    'user_id','user_gender_id', 'user_occupation_id','item_id', 'item_brand_id', 'item_city_id',\n",
    "    'item_category_list_bin1','item_category_list_bin2','shop_id'\n",
    "]\n",
    "rankList = [\n",
    "    'user_age_level', 'user_star_level','item_price_level', 'item_sales_level','item_collected_level', 'item_pv_level','shop_review_num_level','shop_star_level'\n",
    "]\n",
    "\n",
    "dfAll = interaction_ratio(dfAll,baseList,calList,rankList)'''\n",
    "dfCross = pd.read_csv('../../Data/advertisment/Cache/ratio_rank.csv')\n",
    "dfAll = pd.concat([dfAll,dfCross],axis=1)\n",
    "\n",
    "print(dfAll.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###变量的多组合\n",
    "featCorr = dfAll[featBase].corr('spearman')\n",
    "for i in range(len(featBase)-1):\n",
    "    for j in range(i+1,len(featBase)):\n",
    "        try: tmpBound = featCorr.loc[featBase[i],featBase[j]]\n",
    "        except: continue\n",
    "        if abs(tmpBound)>=0.5:\n",
    "            continue\n",
    "        baseName = '~'.join([featBase[i],featBase[j]])+'_com'\n",
    "        dfAll[baseName] = dfAll[[featBase[i],featBase[j]]].apply(lambda x: str(x[0])+'_'+str(x[1]),axis=1)\n",
    "print(dfAll.shape)\n",
    "\n",
    "#dfAll.to_csv(\"../../Data/advertisment/Cache/All_multi_combination.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [i for i in dfAll.columns.tolist() if not i in config.IGNORE_COLS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#0099ff size=5 face=\"黑体\">拆分样本</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_idx = dfTrain.loc[(dfTrain['day']<24)&(dfTrain['day']>18)].index\n",
    "valid_idx = dfTrain.loc[dfTrain['day']==24].index\n",
    "Xi_train_, y_train_ = dfAll.loc[list(train_idx),features],dfTrain.loc[train_idx,'is_trade']\n",
    "Xi_valid_, y_valid_ = dfAll.loc[list(valid_idx),features],dfTrain.loc[valid_idx,'is_trade']\n",
    "Xi_test_ = dfAll.loc[trainNum:,features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#0099ff size=5 face=\"黑体\">模型</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo Mao\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is []\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.647686\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[2]\tvalid_0's binary_logloss: 0.606573\n",
      "[3]\tvalid_0's binary_logloss: 0.569202\n",
      "[4]\tvalid_0's binary_logloss: 0.535116\n",
      "[5]\tvalid_0's binary_logloss: 0.503915\n",
      "[6]\tvalid_0's binary_logloss: 0.475197\n",
      "[7]\tvalid_0's binary_logloss: 0.448711\n",
      "[8]\tvalid_0's binary_logloss: 0.424384\n",
      "[9]\tvalid_0's binary_logloss: 0.401906\n",
      "[10]\tvalid_0's binary_logloss: 0.381068\n",
      "[11]\tvalid_0's binary_logloss: 0.361702\n",
      "[12]\tvalid_0's binary_logloss: 0.343764\n",
      "[13]\tvalid_0's binary_logloss: 0.327075\n",
      "[14]\tvalid_0's binary_logloss: 0.311557\n",
      "[15]\tvalid_0's binary_logloss: 0.297073\n",
      "[16]\tvalid_0's binary_logloss: 0.283517\n",
      "[17]\tvalid_0's binary_logloss: 0.270914\n",
      "[18]\tvalid_0's binary_logloss: 0.259107\n",
      "[19]\tvalid_0's binary_logloss: 0.248061\n",
      "[20]\tvalid_0's binary_logloss: 0.237723\n",
      "[21]\tvalid_0's binary_logloss: 0.228051\n",
      "[22]\tvalid_0's binary_logloss: 0.218989\n",
      "[23]\tvalid_0's binary_logloss: 0.210451\n",
      "[24]\tvalid_0's binary_logloss: 0.202492\n",
      "[25]\tvalid_0's binary_logloss: 0.195012\n",
      "[26]\tvalid_0's binary_logloss: 0.18799\n",
      "[27]\tvalid_0's binary_logloss: 0.181396\n",
      "[28]\tvalid_0's binary_logloss: 0.175223\n",
      "[29]\tvalid_0's binary_logloss: 0.169415\n",
      "[30]\tvalid_0's binary_logloss: 0.16395\n",
      "[31]\tvalid_0's binary_logloss: 0.158822\n",
      "[32]\tvalid_0's binary_logloss: 0.15401\n",
      "[33]\tvalid_0's binary_logloss: 0.149472\n",
      "[34]\tvalid_0's binary_logloss: 0.145229\n",
      "[35]\tvalid_0's binary_logloss: 0.141226\n",
      "[36]\tvalid_0's binary_logloss: 0.137459\n",
      "[37]\tvalid_0's binary_logloss: 0.133917\n",
      "[38]\tvalid_0's binary_logloss: 0.130588\n",
      "[39]\tvalid_0's binary_logloss: 0.127468\n",
      "[40]\tvalid_0's binary_logloss: 0.124535\n",
      "[41]\tvalid_0's binary_logloss: 0.121788\n",
      "[42]\tvalid_0's binary_logloss: 0.119186\n",
      "[43]\tvalid_0's binary_logloss: 0.116757\n",
      "[44]\tvalid_0's binary_logloss: 0.114465\n",
      "[45]\tvalid_0's binary_logloss: 0.11232\n",
      "[46]\tvalid_0's binary_logloss: 0.110308\n",
      "[47]\tvalid_0's binary_logloss: 0.108406\n",
      "[48]\tvalid_0's binary_logloss: 0.106618\n",
      "[49]\tvalid_0's binary_logloss: 0.10494\n",
      "[50]\tvalid_0's binary_logloss: 0.103381\n",
      "[51]\tvalid_0's binary_logloss: 0.101932\n",
      "[52]\tvalid_0's binary_logloss: 0.100555\n",
      "[53]\tvalid_0's binary_logloss: 0.0992855\n",
      "[54]\tvalid_0's binary_logloss: 0.0980787\n",
      "[55]\tvalid_0's binary_logloss: 0.0969199\n",
      "[56]\tvalid_0's binary_logloss: 0.0958646\n",
      "[57]\tvalid_0's binary_logloss: 0.0948553\n",
      "[58]\tvalid_0's binary_logloss: 0.0939407\n",
      "[59]\tvalid_0's binary_logloss: 0.0930962\n",
      "[60]\tvalid_0's binary_logloss: 0.0922706\n",
      "[61]\tvalid_0's binary_logloss: 0.0914901\n",
      "[62]\tvalid_0's binary_logloss: 0.0907925\n",
      "[63]\tvalid_0's binary_logloss: 0.0901121\n",
      "[64]\tvalid_0's binary_logloss: 0.0894692\n",
      "[65]\tvalid_0's binary_logloss: 0.088873\n",
      "[66]\tvalid_0's binary_logloss: 0.0883234\n",
      "[67]\tvalid_0's binary_logloss: 0.0878009\n",
      "[68]\tvalid_0's binary_logloss: 0.0873072\n",
      "[69]\tvalid_0's binary_logloss: 0.0868513\n",
      "[70]\tvalid_0's binary_logloss: 0.0864199\n",
      "[71]\tvalid_0's binary_logloss: 0.086031\n",
      "[72]\tvalid_0's binary_logloss: 0.0856868\n",
      "[73]\tvalid_0's binary_logloss: 0.0853375\n",
      "[74]\tvalid_0's binary_logloss: 0.0850366\n",
      "[75]\tvalid_0's binary_logloss: 0.0847529\n",
      "[76]\tvalid_0's binary_logloss: 0.0844756\n",
      "[77]\tvalid_0's binary_logloss: 0.0842137\n",
      "[78]\tvalid_0's binary_logloss: 0.0839655\n",
      "[79]\tvalid_0's binary_logloss: 0.0837351\n",
      "[80]\tvalid_0's binary_logloss: 0.0835302\n",
      "[81]\tvalid_0's binary_logloss: 0.0833319\n",
      "[82]\tvalid_0's binary_logloss: 0.0831381\n",
      "[83]\tvalid_0's binary_logloss: 0.0829551\n",
      "[84]\tvalid_0's binary_logloss: 0.0827786\n",
      "[85]\tvalid_0's binary_logloss: 0.0826285\n",
      "[86]\tvalid_0's binary_logloss: 0.0824866\n",
      "[87]\tvalid_0's binary_logloss: 0.0823751\n",
      "[88]\tvalid_0's binary_logloss: 0.0822593\n",
      "[89]\tvalid_0's binary_logloss: 0.082151\n",
      "[90]\tvalid_0's binary_logloss: 0.0820571\n",
      "[91]\tvalid_0's binary_logloss: 0.0819641\n",
      "[92]\tvalid_0's binary_logloss: 0.0818814\n",
      "[93]\tvalid_0's binary_logloss: 0.0817886\n",
      "[94]\tvalid_0's binary_logloss: 0.0817031\n",
      "[95]\tvalid_0's binary_logloss: 0.0816268\n",
      "[96]\tvalid_0's binary_logloss: 0.0815709\n",
      "[97]\tvalid_0's binary_logloss: 0.0815054\n",
      "[98]\tvalid_0's binary_logloss: 0.0814382\n",
      "[99]\tvalid_0's binary_logloss: 0.0813653\n",
      "[100]\tvalid_0's binary_logloss: 0.0813079\n",
      "[101]\tvalid_0's binary_logloss: 0.0812525\n",
      "[102]\tvalid_0's binary_logloss: 0.0812192\n",
      "[103]\tvalid_0's binary_logloss: 0.0811899\n",
      "[104]\tvalid_0's binary_logloss: 0.0811496\n",
      "[105]\tvalid_0's binary_logloss: 0.0811223\n",
      "[106]\tvalid_0's binary_logloss: 0.0810802\n",
      "[107]\tvalid_0's binary_logloss: 0.08105\n",
      "[108]\tvalid_0's binary_logloss: 0.0810284\n",
      "[109]\tvalid_0's binary_logloss: 0.0810094\n",
      "[110]\tvalid_0's binary_logloss: 0.0809756\n",
      "[111]\tvalid_0's binary_logloss: 0.080964\n",
      "[112]\tvalid_0's binary_logloss: 0.0809399\n",
      "[113]\tvalid_0's binary_logloss: 0.0809261\n",
      "[114]\tvalid_0's binary_logloss: 0.0809049\n",
      "[115]\tvalid_0's binary_logloss: 0.0808843\n",
      "[116]\tvalid_0's binary_logloss: 0.0808704\n",
      "[117]\tvalid_0's binary_logloss: 0.080851\n",
      "[118]\tvalid_0's binary_logloss: 0.0808514\n",
      "[119]\tvalid_0's binary_logloss: 0.0808363\n",
      "[120]\tvalid_0's binary_logloss: 0.0808196\n",
      "[121]\tvalid_0's binary_logloss: 0.080805\n",
      "[122]\tvalid_0's binary_logloss: 0.0808044\n",
      "[123]\tvalid_0's binary_logloss: 0.0807837\n",
      "[124]\tvalid_0's binary_logloss: 0.0807534\n",
      "[125]\tvalid_0's binary_logloss: 0.0807398\n",
      "[126]\tvalid_0's binary_logloss: 0.0807257\n",
      "[127]\tvalid_0's binary_logloss: 0.0807189\n",
      "[128]\tvalid_0's binary_logloss: 0.0807023\n",
      "[129]\tvalid_0's binary_logloss: 0.0806706\n",
      "[130]\tvalid_0's binary_logloss: 0.0806647\n",
      "[131]\tvalid_0's binary_logloss: 0.0806582\n",
      "[132]\tvalid_0's binary_logloss: 0.0806412\n",
      "[133]\tvalid_0's binary_logloss: 0.080643\n",
      "[134]\tvalid_0's binary_logloss: 0.0806504\n",
      "[135]\tvalid_0's binary_logloss: 0.0806473\n",
      "[136]\tvalid_0's binary_logloss: 0.0806515\n",
      "[137]\tvalid_0's binary_logloss: 0.0806526\n",
      "[138]\tvalid_0's binary_logloss: 0.0806454\n",
      "[139]\tvalid_0's binary_logloss: 0.0806371\n",
      "[140]\tvalid_0's binary_logloss: 0.0806363\n",
      "[141]\tvalid_0's binary_logloss: 0.080625\n",
      "[142]\tvalid_0's binary_logloss: 0.0806185\n",
      "[143]\tvalid_0's binary_logloss: 0.0806126\n",
      "[144]\tvalid_0's binary_logloss: 0.0806119\n",
      "[145]\tvalid_0's binary_logloss: 0.0805968\n",
      "[146]\tvalid_0's binary_logloss: 0.0805965\n",
      "[147]\tvalid_0's binary_logloss: 0.0805917\n",
      "[148]\tvalid_0's binary_logloss: 0.0805926\n",
      "[149]\tvalid_0's binary_logloss: 0.0805901\n",
      "[150]\tvalid_0's binary_logloss: 0.080587\n",
      "[151]\tvalid_0's binary_logloss: 0.0806022\n",
      "[152]\tvalid_0's binary_logloss: 0.0805961\n",
      "[153]\tvalid_0's binary_logloss: 0.0805771\n",
      "[154]\tvalid_0's binary_logloss: 0.0805802\n",
      "[155]\tvalid_0's binary_logloss: 0.0805842\n",
      "[156]\tvalid_0's binary_logloss: 0.0805779\n",
      "[157]\tvalid_0's binary_logloss: 0.0805611\n",
      "[158]\tvalid_0's binary_logloss: 0.0805595\n",
      "[159]\tvalid_0's binary_logloss: 0.0805406\n",
      "[160]\tvalid_0's binary_logloss: 0.0805357\n",
      "[161]\tvalid_0's binary_logloss: 0.0805361\n",
      "[162]\tvalid_0's binary_logloss: 0.0805426\n",
      "[163]\tvalid_0's binary_logloss: 0.0805524\n",
      "[164]\tvalid_0's binary_logloss: 0.0805544\n",
      "[165]\tvalid_0's binary_logloss: 0.0805573\n",
      "[166]\tvalid_0's binary_logloss: 0.0805448\n",
      "[167]\tvalid_0's binary_logloss: 0.0805407\n",
      "[168]\tvalid_0's binary_logloss: 0.080545\n",
      "[169]\tvalid_0's binary_logloss: 0.0805452\n",
      "[170]\tvalid_0's binary_logloss: 0.0805548\n",
      "[171]\tvalid_0's binary_logloss: 0.0805509\n",
      "[172]\tvalid_0's binary_logloss: 0.080555\n",
      "[173]\tvalid_0's binary_logloss: 0.0805449\n",
      "[174]\tvalid_0's binary_logloss: 0.0805671\n",
      "[175]\tvalid_0's binary_logloss: 0.0805698\n",
      "[176]\tvalid_0's binary_logloss: 0.0805745\n",
      "[177]\tvalid_0's binary_logloss: 0.0805888\n",
      "[178]\tvalid_0's binary_logloss: 0.080587\n",
      "[179]\tvalid_0's binary_logloss: 0.0805818\n",
      "[180]\tvalid_0's binary_logloss: 0.0805856\n",
      "[181]\tvalid_0's binary_logloss: 0.0805906\n",
      "[182]\tvalid_0's binary_logloss: 0.080591\n",
      "[183]\tvalid_0's binary_logloss: 0.0805773\n",
      "[184]\tvalid_0's binary_logloss: 0.0805823\n",
      "[185]\tvalid_0's binary_logloss: 0.0805835\n",
      "[186]\tvalid_0's binary_logloss: 0.0805914\n",
      "[187]\tvalid_0's binary_logloss: 0.0806017\n",
      "[188]\tvalid_0's binary_logloss: 0.0805968\n",
      "[189]\tvalid_0's binary_logloss: 0.0806028\n",
      "[190]\tvalid_0's binary_logloss: 0.0806026\n",
      "[191]\tvalid_0's binary_logloss: 0.0805992\n",
      "[192]\tvalid_0's binary_logloss: 0.0806034\n",
      "[193]\tvalid_0's binary_logloss: 0.080616\n",
      "[194]\tvalid_0's binary_logloss: 0.0806214\n",
      "[195]\tvalid_0's binary_logloss: 0.0806125\n",
      "[196]\tvalid_0's binary_logloss: 0.0806142\n",
      "[197]\tvalid_0's binary_logloss: 0.0806139\n",
      "[198]\tvalid_0's binary_logloss: 0.0806177\n",
      "[199]\tvalid_0's binary_logloss: 0.0806118\n",
      "[200]\tvalid_0's binary_logloss: 0.080624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[201]\tvalid_0's binary_logloss: 0.0806207\n",
      "[202]\tvalid_0's binary_logloss: 0.0806132\n",
      "[203]\tvalid_0's binary_logloss: 0.0806224\n",
      "[204]\tvalid_0's binary_logloss: 0.0806266\n",
      "[205]\tvalid_0's binary_logloss: 0.0806265\n",
      "[206]\tvalid_0's binary_logloss: 0.0806274\n",
      "[207]\tvalid_0's binary_logloss: 0.0806292\n",
      "[208]\tvalid_0's binary_logloss: 0.080643\n",
      "[209]\tvalid_0's binary_logloss: 0.0806307\n",
      "[210]\tvalid_0's binary_logloss: 0.0806275\n",
      "[211]\tvalid_0's binary_logloss: 0.0806277\n",
      "[212]\tvalid_0's binary_logloss: 0.0806414\n",
      "[213]\tvalid_0's binary_logloss: 0.0806425\n",
      "[214]\tvalid_0's binary_logloss: 0.0806537\n",
      "[215]\tvalid_0's binary_logloss: 0.0806515\n",
      "[216]\tvalid_0's binary_logloss: 0.0806682\n",
      "[217]\tvalid_0's binary_logloss: 0.0806753\n",
      "[218]\tvalid_0's binary_logloss: 0.0806731\n",
      "[219]\tvalid_0's binary_logloss: 0.0806682\n",
      "[220]\tvalid_0's binary_logloss: 0.0806563\n",
      "[221]\tvalid_0's binary_logloss: 0.0806531\n",
      "[222]\tvalid_0's binary_logloss: 0.0806466\n",
      "[223]\tvalid_0's binary_logloss: 0.0806396\n",
      "[224]\tvalid_0's binary_logloss: 0.0806336\n",
      "[225]\tvalid_0's binary_logloss: 0.0806361\n",
      "[226]\tvalid_0's binary_logloss: 0.0806362\n",
      "[227]\tvalid_0's binary_logloss: 0.0806329\n",
      "[228]\tvalid_0's binary_logloss: 0.0806349\n",
      "[229]\tvalid_0's binary_logloss: 0.080637\n",
      "[230]\tvalid_0's binary_logloss: 0.0806432\n",
      "[231]\tvalid_0's binary_logloss: 0.0806481\n",
      "[232]\tvalid_0's binary_logloss: 0.0806499\n",
      "[233]\tvalid_0's binary_logloss: 0.0806439\n",
      "[234]\tvalid_0's binary_logloss: 0.0806448\n",
      "[235]\tvalid_0's binary_logloss: 0.0806488\n",
      "[236]\tvalid_0's binary_logloss: 0.0806474\n",
      "[237]\tvalid_0's binary_logloss: 0.0806456\n",
      "[238]\tvalid_0's binary_logloss: 0.08065\n",
      "[239]\tvalid_0's binary_logloss: 0.080641\n",
      "[240]\tvalid_0's binary_logloss: 0.0806546\n",
      "[241]\tvalid_0's binary_logloss: 0.0806586\n",
      "[242]\tvalid_0's binary_logloss: 0.0806574\n",
      "[243]\tvalid_0's binary_logloss: 0.0806649\n",
      "[244]\tvalid_0's binary_logloss: 0.0806597\n",
      "[245]\tvalid_0's binary_logloss: 0.0806655\n",
      "[246]\tvalid_0's binary_logloss: 0.0806693\n",
      "[247]\tvalid_0's binary_logloss: 0.0806781\n",
      "[248]\tvalid_0's binary_logloss: 0.0806774\n",
      "[249]\tvalid_0's binary_logloss: 0.0806822\n",
      "[250]\tvalid_0's binary_logloss: 0.0806808\n",
      "[251]\tvalid_0's binary_logloss: 0.0806904\n",
      "[252]\tvalid_0's binary_logloss: 0.0806917\n",
      "[253]\tvalid_0's binary_logloss: 0.080702\n",
      "[254]\tvalid_0's binary_logloss: 0.0806949\n",
      "[255]\tvalid_0's binary_logloss: 0.0806928\n",
      "[256]\tvalid_0's binary_logloss: 0.0806884\n",
      "[257]\tvalid_0's binary_logloss: 0.0806847\n",
      "[258]\tvalid_0's binary_logloss: 0.0806889\n",
      "[259]\tvalid_0's binary_logloss: 0.0806856\n",
      "[260]\tvalid_0's binary_logloss: 0.0806867\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's binary_logloss: 0.0805357\n",
      "                                                 index    0\n",
      "0                                     hour_trade_ratio  168\n",
      "1    user_age_level~user_star_level~item_sales_leve...  154\n",
      "2                                  shop_score_delivery  125\n",
      "3    user_gender_id~user_age_level~item_sales_level...  105\n",
      "4                                  user_id_after_exist   99\n",
      "5                                     item_price_level   94\n",
      "6                          shop_id_user_id_trade_ratio   86\n",
      "7                               len_item_property_list   86\n",
      "8                         shop_id_item_price_level_max   76\n",
      "9                                  item_id_trade_ratio   72\n",
      "10                                user_id_before_exist   68\n",
      "11                                 shop_id_item_id_cnt   68\n",
      "12                user_age_level~item_sales_level_plus   63\n",
      "13                     item_id_shop_score_delivery_min   62\n",
      "14                                                hour   61\n",
      "15                            hour_user_id_trade_ratio   60\n",
      "16                             item_category_list_bin1   58\n",
      "17                          predict_category_property0   55\n",
      "18                          predict_category_property2   55\n",
      "19                         item_id_user_id_trade_ratio   52\n",
      "20                           shop_id_item_id_avg_trade   48\n",
      "21                                   property_gap2_cnt   45\n",
      "22               item_price_level~context_page_id_plus   44\n",
      "23                          predict_category_property1   44\n",
      "24                                        item_city_id   44\n",
      "25                          predict_category_property3   42\n",
      "26   user_gender_id~user_age_level~user_star_level_...   41\n",
      "27                user_gender_id~item_sales_level_plus   39\n",
      "28                  item_id_shop_score_description_min   39\n",
      "29               item_id_shop_review_positive_rate_min   37\n",
      "..                                                 ...  ...\n",
      "304         shop_review_num_level~shop_star_level_plus    1\n",
      "305                             hour_shop_id_trade_cnt    1\n",
      "306                         item_id_user_age_level_min    1\n",
      "307                           hour_user_star_level_min    0\n",
      "308                           hour_context_page_id_min    0\n",
      "309                           hour_context_page_id_max    0\n",
      "310                     hour_shop_review_num_level_min    0\n",
      "311                     hour_shop_review_num_level_max    0\n",
      "312                                  user_id_trade_cnt    0\n",
      "313                 hour_shop_review_positive_rate_max    0\n",
      "314                            hour_user_age_level_min    0\n",
      "315                        hour_shop_score_service_max    0\n",
      "316                       hour_shop_score_delivery_max    0\n",
      "317                    hour_shop_score_description_max    0\n",
      "318                            hour_user_age_level_max    0\n",
      "319                             hour_item_pv_level_min    0\n",
      "320                             hour_item_pv_level_max    0\n",
      "321                          user_id_item_id_trade_cnt    0\n",
      "322                      hour_item_collected_level_max    0\n",
      "323                          hour_item_sales_level_min    0\n",
      "324                          hour_item_price_level_max    0\n",
      "325                          hour_item_price_level_min    0\n",
      "326                        item_id_shop_id_trade_ratio    0\n",
      "327                                item_id_shop_id_cnt    0\n",
      "328                  item_id_shop_review_num_level_max    0\n",
      "329  item_sales_level~item_collected_level~shop_rev...    0\n",
      "330                          user_id_shop_id_avg_trade    0\n",
      "331                        user_id_shop_id_trade_ratio    0\n",
      "332                          user_id_shop_id_trade_cnt    0\n",
      "333                          hour_item_sales_level_max    0\n",
      "\n",
      "[334 rows x 2 columns]\n",
      "0.0805356773742\n",
      "0.316201458176\n"
     ]
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier(\n",
    "    boosting_type = 'gbdt',\n",
    "    num_leaves=35, \n",
    "    max_depth=8,\n",
    "    n_estimators=20000,\n",
    "    n_jobs=20,\n",
    "    learning_rate=0.05,\n",
    "    colsample_bytree=0.8,\n",
    "    subsample=0.9,\n",
    "    max_bin=20\n",
    ")\n",
    "clf.fit(Xi_train_[features], y_train_, eval_set=[(Xi_valid_[features], y_valid_)],feature_name = features,\n",
    "        categorical_feature=[],early_stopping_rounds=100)\n",
    "#[i for i in ['item_category_list_bin1','item_category_list_bin2'] if i in features]\n",
    "y_score_ = clf.predict_proba(Xi_valid_[features],)[:, 1]\n",
    "\n",
    "print(pd.Series(clf.feature_importances_, features).sort_values(ascending=False).reset_index())\n",
    "print(log_loss(y_valid_, y_score_))\n",
    "print(ks_metric(y_valid_, y_score_))\n",
    "bstIter = clf.best_iteration_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xx = pd.Series(clf.feature_importances_, features).sort_values(ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx.loc[xx['index']=='property_gap1_cnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = xx.loc[xx[0]>10,'index'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(xx<10).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_change(score,base_rate,real_rate):\n",
    "    base_change = np.log(base_rate/(1-base_rate)) - np.log(real_rate/(1-real_rate))\n",
    "    score_adj = np.exp(np.log(score/(1-score)) - base_change)/(np.exp(np.log(score/(1-score)) - base_change)+1)\n",
    "    return score_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_score_adj = score_change(y_score_,y_score_.mean(),y_valid_.mean())\n",
    "print(log_loss(y_valid_, y_score_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo Mao\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is []\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    }
   ],
   "source": [
    "#Xi_finnal_ ,y_finnal_ = np.vstack((Xi_train_,Xi_valid_),np.hstack((y_train_,y_valid_))\n",
    "Xi_finnal_ ,y_finnal_ = pd.concat([Xi_train_,Xi_valid_]), pd.concat([y_train_,y_valid_])\n",
    "clf = lgb.LGBMClassifier(\n",
    "    num_leaves=35, \n",
    "    max_depth=8,\n",
    "    n_estimators=bstIter,\n",
    "    n_jobs=20,\n",
    "    learning_rate=0.05,\n",
    "    colsample_bytree=0.8,\n",
    "    subsample=0.9,\n",
    "    max_bin=20\n",
    ")\n",
    "clf.fit(Xi_finnal_, y_finnal_,\n",
    "        categorical_feature=[])\n",
    "#[i for i in ['item_category_list_bin1','item_category_list_bin2'] if i in features]\n",
    "y_test_meta = np.zeros((dfTest.shape[0], 1), dtype=float)\n",
    "y_test_meta[:,0] += clf.predict_proba(Xi_test_)[:,1]\n",
    "submit = pd.DataFrame({'instance_id':dfTest['instance_id'],'predicted_score':y_test_meta[:,0]})\n",
    "#submit.to_csv('../../Submission/advertisement/gbm_trick_0330.txt', sep=\" \", index=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018304112638721327"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['predicted_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_finnal_.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../../Submission/advertisement/gbm_trick_text_417.txt',sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#submit['predicted_score'] = submit['predicted_score'] - submit['predicted_score'].mean() + 0.016983086400719192\n",
    "#submit.loc[submit['predicted_score']<0,'predicted_score'] =0\n",
    "submit.to_csv('../../Submission/advertisement/gbm_trick_testb_418.txt', sep=\" \", index=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit['predicted_score'] = 0\n",
    "submit.to_csv('../../Submission/advertisement/gbm_trick_testb_418.txt', sep=\" \", index=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['predicted_score'] = score_change(submit['predicted_score'],y_finnal_.mean(),0.016983086400719192)\n",
    "submit['predicted_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit.to_csv('../../Submission/advertisement/gbm_trick_text_adj2_417.txt', sep=\" \", index=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.hstack((y_train_,y_valid_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_meta = np.zeros((dfTest.shape[0], 1), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'instance_id':dfTest['instance_id'],'predicted_score':y_test_meta[:,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit['predicted_score'] = 1.0\n",
    "submit.to_csv('../../Submission/advertisement/test_0330.txt', sep=\" \", index=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

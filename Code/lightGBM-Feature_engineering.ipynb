{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import config\n",
    "from numba import jit\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder,StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_datetime(value):\n",
    "    return time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(value))\n",
    "\n",
    "def time_feat(df,featList,featName):\n",
    "    '''scaler = StandardScaler()\n",
    "    tmp = df.groupby(featList).size().reset_index().rename(columns={0:featName})\n",
    "    tmp[featName] = scaler.fit_transform(tmp[featName].values.reshape(-1,1))\n",
    "    df = df.merge(tmp,'left',on=featList)'''\n",
    "    df[featName] = df.groupby(featList)['context_timestamp'].rank(method='first')   \n",
    "    return df\n",
    "\n",
    "def process(df):\n",
    "    df['time'] = df.context_timestamp.apply(timestamp_datetime)\n",
    "    df['day'] = df.time.apply(lambda x: int(x[8:10]))\n",
    "    df['hour'] = df.time.apply(lambda x: int(x[11:13]))\n",
    "    '''for lst in timeFeatList:\n",
    "        df = time_feat(df,lst,'_'.join(lst))'''\n",
    "    df['item_property_list_clean'] = df['item_property_list'].apply(lambda x:';'.join(sorted(set(str(x).split(';')))))\n",
    "    for i in range(3):\n",
    "        df['item_category_list_bin%d'%i] = df['item_category_list'].apply(lambda x: x.split(';')[i] if len(x.split(';'))>i else -1)\n",
    "    del df['item_category_list_bin0']\n",
    "    df[\"missing_feat\"] = np.sum((df == -1).values, axis=1)\n",
    "    return df\n",
    "\n",
    "def labelencoder(df):\n",
    "    lbl = LabelEncoder()\n",
    "    for var in ['user_id','item_id','shop_id','item_brand_id','item_city_id']:\n",
    "        df[var] = lbl.fit_transform(df[var])\n",
    "    return df\n",
    "        \n",
    "\n",
    "def focus_one_record(df,key_var=[],time_diff=False):\n",
    "    if not isinstance(key_var,list):\n",
    "        key_var = [key_var]\n",
    "    nameBase = '_'.join(key_var)\n",
    "    ###当天前后的数据情况\n",
    "    df[nameBase+'_before_cnt'] = df.groupby(key_var+['day'])['context_timestamp'].rank(method='min') - 1\n",
    "    df[nameBase+'_after_cnt'] = df.groupby(key_var+['day'])['context_timestamp'].rank(method='min',ascending=False)- 1\n",
    "    df[nameBase+'_sametime_cnt'] = df.groupby(key_var+['day'])['context_timestamp'].rank(method='max') - df.groupby(key_var+['day'])['context_timestamp'].rank(method='min')+1\n",
    "    df = df.merge(df.groupby(key_var+['day'],as_index=False)['context_timestamp'].agg({nameBase+'_day_cnt':'count'}),'inner',key_var+['day'])\n",
    "    for feat in ['_before_cnt','_after_cnt','_sametime_cnt']:\n",
    "        df[nameBase+feat+'_ratio'] = df[nameBase+feat]*1.0/df[nameBase+'_day_cnt']\n",
    "                \n",
    "    ###前一天购买/浏览的数量\n",
    "    '''dfTmp =  df.groupby(key_var+['day'],as_index=False)['is_trade'].agg({nameBase+'_preday_trade_cnt':'sum',nameBase+'_preday_cnt':'count'})\n",
    "    dfTmp['day'] = dfTmp['day']+1\n",
    "    df = df.merge(dfTmp,'left',key_var+['day'])\n",
    "    df[nameBase+'_preday_trade_ratio'] = df[nameBase+'_preday_trade_cnt']*1.0/df[nameBase+'_preday_cnt']\n",
    "    for feat in ['_preday_trade_cnt','_preday_cnt','_preday_trade_ratio']:\n",
    "        df[nameBase+feat].fillna(0,inplace=True)'''\n",
    "        \n",
    "    if time_diff:\n",
    "        ###广告展示上下间隔\n",
    "        dfTmp = df[[nameBase+'_before_cnt',nameBase+'_after_cnt',nameBase+'_sametime_cnt','time']+key_var+['day']]\n",
    "        dfTmp.rename(columns={'time':'new_time'},inplace=True)\n",
    "        dfTmp['next_record'] = dfTmp[nameBase+'_before_cnt'] + dfTmp[nameBase+'_sametime_cnt'] + 1\n",
    "        dfTmp['last_record'] = dfTmp[nameBase+'_after_cnt'] + dfTmp[nameBase+'_sametime_cnt'] + 1\n",
    "        df = df.merge(dfTmp[key_var+['day','next_record','new_time']],'left',left_on = key_var+['day',nameBase+'_before_cnt'],right_on = key_var+['day','next_record'])\n",
    "        df[nameBase + '_next_time_dur'] = (pd.to_datetime(df['time'])-pd.to_datetime(df['new_time'])).dt.seconds\n",
    "        df[nameBase + '_next_time_dur'].fillna(999999,inplace=True)\n",
    "        df.loc[df[nameBase+'_sametime_cnt']>1,nameBase + '_next_time_dur'] = 0\n",
    "        del df['new_time']\n",
    "        del df['next_record']\n",
    "\n",
    "        df = df.merge(dfTmp[key_var+['day','last_record','new_time']],'left',left_on = key_var+['day',nameBase+'_after_cnt'],right_on = key_var+['day','last_record'])\n",
    "        df[nameBase + '_last_time_dur'] = (pd.to_datetime(df['new_time'])-pd.to_datetime(df['time'])).dt.seconds\n",
    "        df[nameBase + '_last_time_dur'].fillna(999999,inplace=True)\n",
    "        df.loc[df[nameBase+'_sametime_cnt']>1,nameBase + '_last_time_dur'] = 0\n",
    "        del df['new_time']\n",
    "        del df['last_record']\n",
    "    for feat in ['_before_cnt','_after_cnt','_sametime_cnt']:\n",
    "        del df[nameBase+feat]\n",
    "    return df    \n",
    "    \n",
    "def Discretize(vlu, list_cat, greedy_f=False):\n",
    "    if len(list_cat) == 0:\n",
    "        return set([str(vlu)])\n",
    "    cut_l = ['-Inf'] + [str(i) for i in list_cat if i < vlu]\n",
    "    cut_h = [str(i) for i in list_cat if i >= vlu] + ['Inf']\n",
    "    if greedy_f:\n",
    "        return set([i + '_' + j for i in cut_l for j in cut_h])\n",
    "    else:\n",
    "        return set([cut_l[-1] + '_' + cut_h[0]])\n",
    "    \n",
    "def Discretization(rec, dict_cat, greedy_f=False):\n",
    "    return (dict([(key, Discretize(rec[key], dict_cat[key], greedy_f)) for key in dict_cat]))\n",
    "\n",
    "def cat_str(rec, dict_cat, greedy_f=False):\n",
    "    cat_tag = Discretization(rec, dict_cat, greedy_f=False)\n",
    "    flat_list = ';'.join([key + '_' + str(item) for key in cat_tag.keys() for item in cat_tag[key]])\n",
    "    return (flat_list)\n",
    "\n",
    "@jit\n",
    "def _agg_df(df, grp_key, sum_var, cnt_var, stat_var):\n",
    "    grouped = df.groupby(grp_key)\n",
    "    agg_sum = grouped[sum_var].agg('sum').reset_index().melt(id_vars=grp_key, value_vars=sum_var)\n",
    "    agg_sum['method'] = 'sum'\n",
    "    agg_uniq = grouped[cnt_var].agg('nunique').reset_index().melt(id_vars=grp_key, value_vars=cnt_var)\n",
    "    agg_uniq['method'] = 'cnt'\n",
    "    agg_max = grouped[stat_var].agg('max').reset_index().melt(id_vars=grp_key, value_vars=stat_var)\n",
    "    agg_max['method'] = 'max'\n",
    "    agg_min = grouped[stat_var].agg('min').reset_index().melt(id_vars=grp_key, value_vars=stat_var)\n",
    "    agg_min['method'] = 'min'\n",
    "    agg_mst = pd.concat([agg_sum, agg_uniq, agg_max, agg_min])\n",
    "    return (agg_mst)\n",
    "\n",
    "def _sig_calc(cdr_rec, key_var, TS_cat, dict_cat,sum_var, cnt_var, stat_var):\n",
    "    cdr_dict = cdr_rec.to_dict(orient='records')\n",
    "    cdr_dict = [dict(list(x.items()) + [('TS', '~'.join(list(Discretization(x, TS_cat).values())[0]))] + [\n",
    "        ('cat_str', cat_str(x, dict_cat))]) for x in cdr_dict]\n",
    "    cdr_rec = pd.DataFrame(cdr_dict).reset_index()\n",
    "    # one to many\n",
    "    cat_driver = pd.concat([pd.Series(row['index'], row['cat_str'].split(';'))\n",
    "                            for _, row in cdr_rec.iterrows()]).reset_index()\n",
    "    cat_driver.columns = ['cat', 'index']\n",
    "    cdr_rec_m = pd.merge(cdr_rec, cat_driver, on='index', how='inner')\n",
    "    # Aggregation\n",
    "    if key_var=='':\n",
    "        key_var_tmp = ['TS']\n",
    "    else:\n",
    "        key_var_tmp = key_var+['TS']\n",
    "    agg_mst_m = _agg_df(cdr_rec_m, key_var_tmp+['cat'], sum_var, cnt_var, stat_var)\n",
    "    agg_mst_m['var_name'] = agg_mst_m[['method', 'variable', 'cat']].apply(\n",
    "        lambda x: x[0] + '_' + x[1] + '_cat_' + str(x[2]), axis=1)\n",
    "    if key_var=='':\n",
    "        agg_mst_m['key'] = agg_mst_m[key_var_tmp]\n",
    "    else:\n",
    "        agg_mst_m['key'] = agg_mst_m[key_var_tmp].apply(lambda x: '{0}:{1}'.format(x[0], x[1]), axis=1)\n",
    "    agg_df_m = agg_mst_m.pivot(index='key', columns='var_name', values='value').reset_index()\n",
    "\n",
    "    agg_mst = _agg_df(cdr_rec, key_var_tmp, sum_var, cnt_var, stat_var)\n",
    "    agg_mst['var_name'] = agg_mst[['method', 'variable']].apply(lambda x: x[0] + '_' + x[1] + '_cat_total_all', axis=1)\n",
    "    if key_var=='':\n",
    "        agg_mst['key'] = agg_mst[key_var_tmp]\n",
    "    else:\n",
    "        agg_mst['key'] = agg_mst[key_var_tmp].apply(lambda x: '{0}:{1}'.format(x[0], x[1]), axis=1)\n",
    "    agg_df = agg_mst.pivot(index='key', columns='var_name', values='value').reset_index()\n",
    "\n",
    "    agg_df = pd.merge(agg_df, agg_df_m, on='key', how='left')\n",
    "    \n",
    "    sig_ratio = [sig for sig in agg_df.columns if\n",
    "                 (('sum_' in sig) or ('cnt_' in sig)) and ('cat_total_all' not in sig)]\n",
    "    for sig in sig_ratio:\n",
    "        agg_df['rto_' + sig] = agg_df[[sig, sig.split('cat')[0] + 'cat_total_all']].apply(\n",
    "            lambda x: (x[0] + 0.0) / x[1], axis=1)\n",
    "        del agg_df[sig]\n",
    "    return agg_df\n",
    "\n",
    "def _offline_feat(df,key_var='user_id',stat_var=[],part_var=[],mean_var=[],train_feat_col=None):\n",
    "    if not isinstance(key_var,list):\n",
    "        key_var = [key_var]\n",
    "    left_key = key_var.copy()\n",
    "    if not train_feat_col:\n",
    "        key_var.append(train_feat_col[1])\n",
    "        left_key.append(train_feat_col[0])\n",
    "        \n",
    "    base_name = '~'.join(key_var)\n",
    "    df = df.merge(df.groupby(key_var,as_index=False)['instance_id'].agg({base_name+'_cnt':'count'}),'left',left_on =left_key, right_on = key_var)\n",
    "    df = df.merge(df.groupby(key_var,as_index=False)['is_trade'].agg({base_name+'_trade_cnt':'sum',base_name+'_trade_ratio':'mean'}),'left',left_on =left_key, right_on = key_var)\n",
    "    df[base_name+'_notrade_cnt'] = df[base_name+'_cnt']-df[base_name+'_trade_cnt']\n",
    "    dfTmp = df.loc[df['is_trade']==1]\n",
    "    for stat in stat_var:\n",
    "        df = df.merge(df.groupby(key_var,as_index=False)[stat].agg({base_name+'_'+stat+'_min':'min',base_name+'_'+stat+'_max':'max'}),'left',left_on =left_key, right_on = key_var)    \n",
    "    for part in part_var:\n",
    "        df = df.merge(df.groupby(key_var,as_index=False)[part].agg({base_name+'_'+part+'_cnt':'nunique'}),'left',left_on =left_key, right_on = key_var)\n",
    "        df = df.merge(dfTmp.groupby(key_var,as_index=False)[part].agg({base_name+'_'+part+'_trade_cnt':'nunique'}),'left',left_on =left_key, right_on = key_var)\n",
    "        df[base_name+'_'+part+'_trade_cnt'].fillna(0,inplace=True)\n",
    "        df[base_name+'_'+part+'_trade_ratio'] = 1.0*df[base_name+'_'+part+'_trade_cnt']/df[base_name+'_'+part+'_cnt']\n",
    "    for var in mean_var:\n",
    "        df = df.merge(df.groupby(key_var+[var],as_index=False)['is_trade'].sum().groupby(key_var,as_index=False)['is_trade'].agg({base_name+'_'+var+'_avg_trade':'mean'}),'left',left_on =left_key, right_on = key_var)\n",
    "    return df\n",
    "\n",
    "def map_col(df,drop=False):\n",
    "    map_dict = {\n",
    "        'item_price_level':[4,5,6,7,8,9],\n",
    "        'item_sales_level':[4,6,9,10,11,12,13,14,16],\n",
    "        'item_pv_level':[6,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "        'user_age_level':[1001,1002,1003,1004,1005],\n",
    "        'context_page_id':[4001,4002,4004,4006,4008,4010,4013,4016,4018],\n",
    "        'shop_review_num_level':[5,9,14,15,16,17,18,20,21],\n",
    "        'hour':[6,9,12,17,20],\n",
    "        'user_occupation_id':{-1:2003},\n",
    "        'user_star_level':{-1:3000}\n",
    "    }\n",
    "    for key,value in map_dict.items():\n",
    "        if isinstance(value,list):\n",
    "            df[key+'_mapped'] = 0\n",
    "            for i in range(len(value)):\n",
    "                df.loc[df[key]>value[i],key+'_mapped'] = i+1\n",
    "        else:\n",
    "            '''df[key+'_mapped'] = df[key]\n",
    "            for key_sub,value_sub in value.items():\n",
    "                df.loc[df[key]==key_sub,key+'_mapped'] = value_sub'''\n",
    "            df[key+'_mapped'] = df[key].apply(lambda x:value.get(x,x))\n",
    "        if drop:\n",
    "            df[key] = df[key+'_mapped']\n",
    "            del df[key+'_mapped']\n",
    "    return df\n",
    "\n",
    "def interaction_ratio(df,base_list=[],cal_list=[],rank_list = []):\n",
    "    for base_var in base_list:\n",
    "        if not isinstance(base_var,list):\n",
    "            base_var = [base_var]\n",
    "        if not '_'.join(base_var)+'_cnt' in df.columns:\n",
    "            df = df.merge(df.groupby(base_var,as_index=False)['instance_id'].agg({'_'.join(base_var)+'_cnt':'count'}),'left',base_var)\n",
    "        print('ratio part')\n",
    "        for cal_var in cal_list:\n",
    "            if not isinstance(cal_var,list):\n",
    "                cal_var = [cal_var]\n",
    "            if cal_var==base_var or base_var==['cnt_rec']:\n",
    "                continue\n",
    "            nameBase = '_'.join(base_var)+'~'+'_'.join(cal_var)\n",
    "            print(nameBase)\n",
    "            df = df.merge(df.groupby(base_var+cal_var,as_index=False)['instance_id'].agg({nameBase+'_cnt':'count'}),'left',base_var+cal_var)\n",
    "            df[nameBase+'_ratio'] = df[nameBase+'_cnt']*1.0/df['_'.join(base_var)+'_cnt']\n",
    "            del df[nameBase+'_cnt']\n",
    "        \n",
    "        print('rank part')\n",
    "        for rank_var in rank_list:\n",
    "            if not isinstance(rank_var,list):\n",
    "                rank_var = [rank_var]\n",
    "            if rank_var==base_var:\n",
    "                continue\n",
    "            nameBase = '_'.join(base_var)+'~'+'_'.join(rank_var)\n",
    "            print(nameBase)\n",
    "            df[nameBase+'_rank'] = dfAll.groupby(base_var)[rank_var].rank(method='min')\n",
    "            df[nameBase+'_rank_ratio'] = df[nameBase+'_rank']*1.0/df['_'.join(base_var)+'_cnt']\n",
    "            del df[nameBase+'_rank']\n",
    "        del df['_'.join(base_var)+'_cnt']\n",
    "    return df\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#0099ff size=5 face=\"黑体\">读取数据</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496482, 35)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain = pd.read_table(config.TRAIN_FILE,sep=' ')\n",
    "dfTrain.drop_duplicates(inplace=True)\n",
    "dfTrain.reset_index(inplace=True,drop =True)\n",
    "dfTest = pd.read_table(config.TEST_FILE,sep=' ')\n",
    "\n",
    "dfTrain = process(dfTrain)\n",
    "dfTest = process(dfTest)\n",
    "\n",
    "dfAll = pd.concat([dfTrain,dfTest],axis=0)\n",
    "dfAll.reset_index(inplace=True,drop=True)\n",
    "trainNum = dfTrain.shape[0]\n",
    "dfAll['cnt_rec'] = 1\n",
    "dfAll = labelencoder(dfAll)\n",
    "dfAll.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#0099ff size=5 face=\"黑体\">特征工程</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(496482, 35)\n"
     ]
    }
   ],
   "source": [
    "###单特征map\n",
    "dfAll = map_col(dfAll,True)\n",
    "print(dfAll.shape)\n",
    "featBase = [i for i in dfAll.columns.tolist() if not i in config.IGNORE_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(496482, 121)\n"
     ]
    }
   ],
   "source": [
    "###线下特征集合\n",
    "dfAll['feat_set'] = dfAll['day'] + 1\n",
    "keyList = ['user_id','shop_id','item_id']\n",
    "partList = [\n",
    "    ['item_id','shop_id'],\n",
    "    ['user_id','item_id'],\n",
    "    ['user_id','shop_id']\n",
    "]\n",
    "meanList = [\n",
    "    ['shop_id'],\n",
    "    ['item_id'],\n",
    "    []\n",
    "]\n",
    "for i in range(3):\n",
    "    keyVar = keyList[i]\n",
    "    partVar = partList[i]\n",
    "    meanVar = meanList[i]\n",
    "    statVar = []\n",
    "    if isinstance(keyVar,str):\n",
    "        for key,value in config.STAT_DICT.items():\n",
    "            if key==keyVar:\n",
    "                continue\n",
    "            statVar += value\n",
    "    dfAll = _offline_feat(dfAll,keyVar,statVar,partVar,meanVar,['day','feat_set'])\n",
    "del dfAll['feat_set']\n",
    "print(dfAll.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3027: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(655282, 143)\n"
     ]
    }
   ],
   "source": [
    "###当天信息的trick\n",
    "keyList = ['user_id','shop_id','item_id','item_city_id','item_brand_id']\n",
    "for keyVar in keyList:\n",
    "    timeDiff = False if keyVar=='user_id' else True\n",
    "    dfAll = focus_one_record(dfAll,keyVar,timeDiff)\n",
    "print(dfAll.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio part\n",
      "rank part\n",
      "cnt_rec~user_age_level\n",
      "cnt_rec~user_star_level\n",
      "cnt_rec~item_price_level\n",
      "cnt_rec~item_sales_level\n",
      "cnt_rec~item_collected_level\n",
      "cnt_rec~item_pv_level\n",
      "cnt_rec~shop_review_num_level\n",
      "cnt_rec~shop_star_level\n",
      "ratio part\n",
      "user_id~user_gender_id\n",
      "user_id~user_occupation_id\n",
      "user_id~item_id\n",
      "user_id~item_brand_id\n",
      "user_id~item_city_id\n",
      "user_id~item_category_list_bin1\n",
      "user_id~item_category_list_bin2\n",
      "user_id~shop_id\n",
      "rank part\n",
      "user_id~user_age_level\n",
      "user_id~user_star_level\n",
      "user_id~item_price_level\n",
      "user_id~item_sales_level\n",
      "user_id~item_collected_level\n",
      "user_id~item_pv_level\n",
      "user_id~shop_review_num_level\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a3e0644dbe90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m ]\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mdfAll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minteraction_ratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfAll\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbaseList\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcalList\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrankList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfAll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-a954eb7f542d>\u001b[0m in \u001b[0;36minteraction_ratio\u001b[1;34m(df, base_list, cal_list, rank_list)\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[0mnameBase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'_'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'~'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrank_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnameBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m             \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnameBase\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_rank'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfAll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_var\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m             \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnameBase\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_rank_ratio'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnameBase\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_rank'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_cnt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnameBase\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_rank'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 723\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurried_with_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    724\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    803\u001b[0m         \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mode.chained_assignment'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_python_apply_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m             not_indexed_same=mutated or self.mutated)\n\u001b[0m\u001b[0;32m    815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_iterate_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36m_wrap_applied_output\u001b[1;34m(self, keys, values, not_indexed_same)\u001b[0m\n\u001b[0;32m   3854\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3855\u001b[0m             return self._concat_objects(keys, values,\n\u001b[1;32m-> 3856\u001b[1;33m                                         not_indexed_same=not_indexed_same)\n\u001b[0m\u001b[0;32m   3857\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupings\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3858\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupings\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36m_concat_objects\u001b[1;34m(self, keys, values, not_indexed_same)\u001b[0m\n\u001b[0;32m    974\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnot_indexed_same\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    977\u001b[0m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_selected_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, copy)\u001b[0m\n\u001b[0;32m    210\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m                        copy=copy)\n\u001b[0m\u001b[0;32m    213\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m             \u001b[1;31m# consolidate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m             \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m             \u001b[0mndims\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_consolidate\u001b[1;34m(self, inplace)\u001b[0m\n\u001b[0;32m   3693\u001b[0m         \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inplace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3695\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3696\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3697\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3675\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3677\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3679\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   3664\u001b[0m         \"\"\"\n\u001b[0;32m   3665\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3666\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3667\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3668\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###两两类别变量的比例/rank 顺序\n",
    "baseList = [\n",
    "    'cnt_rec',\n",
    "    'user_id','user_gender_id', 'user_occupation_id','user_age_level', 'user_star_level',\n",
    "    'item_id', 'item_brand_id', 'item_city_id', 'item_price_level', 'item_sales_level','item_collected_level', 'item_pv_level',\n",
    "    'item_category_list_bin1','item_category_list_bin2',\n",
    "    'shop_id', 'shop_review_num_level','shop_star_level'\n",
    "]\n",
    "calList = [\n",
    "    'user_id','user_gender_id', 'user_occupation_id','item_id', 'item_brand_id', 'item_city_id',\n",
    "    'item_category_list_bin1','item_category_list_bin2','shop_id'\n",
    "]\n",
    "rankList = [\n",
    "    'user_age_level', 'user_star_level','item_price_level', 'item_sales_level','item_collected_level', 'item_pv_level','shop_review_num_level','shop_star_level'\n",
    "]\n",
    "\n",
    "dfAll = interaction_ratio(dfAll,baseList,calList,rankList)\n",
    "print(dfAll.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###变量的多组合\n",
    "featCorr = dfAll[featBase].corr('spearman')\n",
    "for i in range(len(featBase)-1):\n",
    "    for j in range(i+1,len(featBase)):\n",
    "        try: tmpBound = featCorr.loc[featBase[i],featBase[j]]\n",
    "        except: continue\n",
    "        if abs(tmpBound)>=0.5:\n",
    "            continue\n",
    "        baseName = '~'.join([featBase[i],featBase[j]])+'_com'\n",
    "        dfAll[baseName] = dfAll[[featBase[i],featBase[j]]].apply(lambda x: str(x[0])+'_'+str(x[1]),axis=1)\n",
    "print(dfAll.shape)\n",
    "\n",
    "#dfAll.to_csv(\"../../Data/advertisment/Cache/All_multi_combination.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [i for i in dfAll.columns.tolist() if not i in config.IGNORE_COLS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#0099ff size=5 face=\"黑体\">拆分样本</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_idx = dfTrain.loc[(dfTrain['day']<24)&(dfTrain['day']>18)].index\n",
    "valid_idx = dfTrain.loc[dfTrain['day']==24].index\n",
    "Xi_train_, y_train_ = dfAll.loc[list(train_idx),features],dfTrain.loc[train_idx,'is_trade']\n",
    "Xi_valid_, y_valid_ = dfAll.loc[list(valid_idx),features],dfTrain.loc[valid_idx,'is_trade']\n",
    "Xi_test_ = dfAll.loc[trainNum:,features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xi_train_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#0099ff size=5 face=\"黑体\">模型</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = lgb.LGBMClassifier(\n",
    "    num_leaves=63, \n",
    "    max_depth=8,\n",
    "    n_estimators=20000,\n",
    "    n_jobs=20,\n",
    "    learning_rate=0.05,\n",
    "    colsample_bytree=0.8,\n",
    "    subsample=0.9,\n",
    "    max_bin=20\n",
    ")\n",
    "clf.fit(Xi_train_, y_train_,\n",
    "        categorical_feature=[],early_stopping_rounds=200)\n",
    "y_score_ = clf.predict_proba(Xi_valid_,)[:, 1]\n",
    "print(log_loss(y_valid_, y_score_))\n",
    "bstIter = clf.best_iteration_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xi_finnal_ ,y_finnal_ = np.vstack((Xi_train_,Xi_valid_)),np.hstack((y_train_,y_valid_))\n",
    "clf = lgb.LGBMClassifier(\n",
    "    num_leaves=63, \n",
    "    max_depth=8,\n",
    "    n_estimators=bstIter,\n",
    "    n_jobs=20,\n",
    "    learning_rate=0.05,\n",
    "    colsample_bytree=0.8,\n",
    "    subsample=0.9,\n",
    "    max_bin=20\n",
    ")\n",
    "clf.fit(Xi_finnal_, y_finnal_,\n",
    "        categorical_feature=[])\n",
    "y_test_meta = np.zeros((dfTest.shape[0], 1), dtype=float)\n",
    "y_test_meta[:,0] += clf.predict_proba(Xi_test_)[:,1]\n",
    "submit = pd.DataFrame({'instance_id':dfTest['instance_id'],'predicted_score':y_test_meta[:,0]})\n",
    "submit.to_csv('../../Submission/advertisement/gbm_trick_0330.txt', sep=\" \", index=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.hstack((y_train_,y_valid_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_meta = np.zeros((dfTest.shape[0], 1), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'instance_id':dfTest['instance_id'],'predicted_score':y_test_meta[:,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit['predicted_score'] = 1.0\n",
    "submit.to_csv('../../Submission/advertisement/test_0330.txt', sep=\" \", index=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import config\n",
    "from numba import jit\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.metrics import log_loss,roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder,StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from itertools import chain, combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timestamp_datetime(value):\n",
    "    return time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(value))\n",
    "\n",
    "def time_feat(df,featList,featName):\n",
    "    '''scaler = StandardScaler()\n",
    "    tmp = df.groupby(featList).size().reset_index().rename(columns={0:featName})\n",
    "    tmp[featName] = scaler.fit_transform(tmp[featName].values.reshape(-1,1))\n",
    "    df = df.merge(tmp,'left',on=featList)'''\n",
    "    df[featName] = df.groupby(featList)['context_timestamp'].rank(method='first')   \n",
    "    return df\n",
    "\n",
    "def process(df):\n",
    "    df['time'] = df.context_timestamp.apply(timestamp_datetime)\n",
    "    df['day'] = df.time.apply(lambda x: int(x[8:10]))\n",
    "    df['hour'] = df.time.apply(lambda x: int(x[11:13]))\n",
    "    '''for lst in timeFeatList:\n",
    "        df = time_feat(df,lst,'_'.join(lst))'''\n",
    "    df['item_property_list'] = df['item_property_list'].apply(lambda x:';'.join(sorted(set(str(x).split(';')))))\n",
    "    df['predict_category_property'] = df['predict_category_property'].apply(lambda x:';'.join(sorted(set(str(x).split(';')))))\n",
    "    df['len_item_property_list'] = df['item_property_list'].apply(lambda x: len(str(x).split(';')))\n",
    "    df['len_predict_category_property'] = df['predict_category_property'].apply(lambda x: len(str(x).split(';')))\n",
    "    lbl = LabelEncoder()\n",
    "    for i in range(1,3):\n",
    "        df['item_category_list_bin%d'%i] = lbl.fit_transform(df['item_category_list'].apply(lambda x: x.split(';')[i] if len(x.split(';'))>i else ''))\n",
    "    for i in range(10):\n",
    "        df['predict_category_property%d'%i] = lbl.fit_transform(df['predict_category_property'].apply(lambda x: x.split(';')[i] if len(x.split(';'))>i else ''))\n",
    "    \n",
    "    #df[\"missing_feat\"] = np.sum((df == -1).values, axis=1)\n",
    "    return df\n",
    "\n",
    "def labelencoder(df):\n",
    "    lbl = LabelEncoder()\n",
    "    for var in ['user_id','item_id','shop_id','item_brand_id','item_city_id']:\n",
    "        df[var] = lbl.fit_transform(df[var])\n",
    "    return df\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "def same_day_trick(df,key_var=[]):\n",
    "    if not isinstance(key_var,list):\n",
    "        key_var = [key_var]\n",
    "    nameBase = '_'.join(key_var)\n",
    "    ###当天前后的数据情况\n",
    "    df[nameBase+'_before_exist'] = ((df.groupby(key_var+['day'])['context_timestamp'].rank(method='min') - 1) > 0).astype(int)\n",
    "    df[nameBase+'_after_exist'] = ((df.groupby(key_var+['day'])['context_timestamp'].rank(method='min',ascending=False)- 1) > 0).astype(int)\n",
    "    df[nameBase+'_sametime_exist'] = ((df.groupby(key_var+['day'])['context_timestamp'].rank(method='max') - df.groupby(key_var+['day'])['context_timestamp'].rank(method='min')) > 0).astype(int)\n",
    "    #df = df.merge(df.groupby(key_var+['day'],as_index=False)['context_timestamp'].agg({nameBase+'_day_cnt':'count'}),'inner',key_var+['day'])\n",
    "    return df    \n",
    "\n",
    "def focus_one_record(df,key_var=[],time_diff=False):\n",
    "    if not isinstance(key_var,list):\n",
    "        key_var = [key_var]\n",
    "    nameBase = '_'.join(key_var)\n",
    "    ###当天前后的数据情况\n",
    "    df[nameBase+'_before_cnt'] = df.groupby(key_var+['day'])['context_timestamp'].rank(method='min') - 1\n",
    "    df[nameBase+'_after_cnt'] = df.groupby(key_var+['day'])['context_timestamp'].rank(method='min',ascending=False)- 1\n",
    "    df[nameBase+'_sametime_cnt'] = df.groupby(key_var+['day'])['context_timestamp'].rank(method='max') - df.groupby(key_var+['day'])['context_timestamp'].rank(method='min')+1\n",
    "    df = df.merge(df.groupby(key_var+['day'],as_index=False)['context_timestamp'].agg({nameBase+'_day_cnt':'count'}),'inner',key_var+['day'])\n",
    "    for feat in ['_before_cnt','_after_cnt','_sametime_cnt']:\n",
    "        df[nameBase+feat+'_ratio'] = df[nameBase+feat]*1.0/df[nameBase+'_day_cnt']\n",
    "                \n",
    "    ###前一天购买/浏览的数量\n",
    "    '''dfTmp =  df.groupby(key_var+['day'],as_index=False)['is_trade'].agg({nameBase+'_preday_trade_cnt':'sum',nameBase+'_preday_cnt':'count'})\n",
    "    dfTmp['day'] = dfTmp['day']+1\n",
    "    df = df.merge(dfTmp,'left',key_var+['day'])\n",
    "    df[nameBase+'_preday_trade_ratio'] = df[nameBase+'_preday_trade_cnt']*1.0/df[nameBase+'_preday_cnt']\n",
    "    for feat in ['_preday_trade_cnt','_preday_cnt','_preday_trade_ratio']:\n",
    "        df[nameBase+feat].fillna(0,inplace=True)'''\n",
    "        \n",
    "    if time_diff:\n",
    "        ###广告展示上下间隔\n",
    "        dfTmp = df[[nameBase+'_before_cnt',nameBase+'_after_cnt',nameBase+'_sametime_cnt','time']+key_var+['day']]\n",
    "        dfTmp.rename(columns={'time':'new_time'},inplace=True)\n",
    "        dfTmp['next_record'] = dfTmp[nameBase+'_before_cnt'] + dfTmp[nameBase+'_sametime_cnt'] + 1\n",
    "        dfTmp['last_record'] = dfTmp[nameBase+'_after_cnt'] + dfTmp[nameBase+'_sametime_cnt'] + 1\n",
    "        df = df.merge(dfTmp[key_var+['day','next_record','new_time']],'left',left_on = key_var+['day',nameBase+'_before_cnt'],right_on = key_var+['day','next_record'])\n",
    "        df[nameBase + '_next_time_dur'] = (pd.to_datetime(df['time'])-pd.to_datetime(df['new_time'])).dt.seconds\n",
    "        df[nameBase + '_next_time_dur'].fillna(999999,inplace=True)\n",
    "        df.loc[df[nameBase+'_sametime_cnt']>1,nameBase + '_next_time_dur'] = 0\n",
    "        del df['new_time']\n",
    "        del df['next_record']\n",
    "\n",
    "        df = df.merge(dfTmp[key_var+['day','last_record','new_time']],'left',left_on = key_var+['day',nameBase+'_after_cnt'],right_on = key_var+['day','last_record'])\n",
    "        df[nameBase + '_last_time_dur'] = (pd.to_datetime(df['new_time'])-pd.to_datetime(df['time'])).dt.seconds\n",
    "        df[nameBase + '_last_time_dur'].fillna(999999,inplace=True)\n",
    "        df.loc[df[nameBase+'_sametime_cnt']>1,nameBase + '_last_time_dur'] = 0\n",
    "        del df['new_time']\n",
    "        del df['last_record']\n",
    "    for feat in ['_before_cnt','_after_cnt','_sametime_cnt']:\n",
    "        del df[nameBase+feat]\n",
    "    return df    \n",
    "    \n",
    "def Discretize(vlu, list_cat, greedy_f=False):\n",
    "    if len(list_cat) == 0:\n",
    "        return set([str(vlu)])\n",
    "    cut_l = ['-Inf'] + [str(i) for i in list_cat if i < vlu]\n",
    "    cut_h = [str(i) for i in list_cat if i >= vlu] + ['Inf']\n",
    "    if greedy_f:\n",
    "        return set([i + '_' + j for i in cut_l for j in cut_h])\n",
    "    else:\n",
    "        return set([cut_l[-1] + '_' + cut_h[0]])\n",
    "    \n",
    "def Discretization(rec, dict_cat, greedy_f=False):\n",
    "    return (dict([(key, Discretize(rec[key], dict_cat[key], greedy_f)) for key in dict_cat]))\n",
    "\n",
    "def cat_str(rec, dict_cat, greedy_f=False):\n",
    "    cat_tag = Discretization(rec, dict_cat, greedy_f=False)\n",
    "    flat_list = ';'.join([key + '_' + str(item) for key in cat_tag.keys() for item in cat_tag[key]])\n",
    "    return (flat_list)\n",
    "\n",
    "@jit\n",
    "def _agg_df(df, grp_key, sum_var, cnt_var, stat_var):\n",
    "    grouped = df.groupby(grp_key)\n",
    "    agg_sum = grouped[sum_var].agg('sum').reset_index().melt(id_vars=grp_key, value_vars=sum_var)\n",
    "    agg_sum['method'] = 'sum'\n",
    "    agg_uniq = grouped[cnt_var].agg('nunique').reset_index().melt(id_vars=grp_key, value_vars=cnt_var)\n",
    "    agg_uniq['method'] = 'cnt'\n",
    "    agg_max = grouped[stat_var].agg('max').reset_index().melt(id_vars=grp_key, value_vars=stat_var)\n",
    "    agg_max['method'] = 'max'\n",
    "    agg_min = grouped[stat_var].agg('min').reset_index().melt(id_vars=grp_key, value_vars=stat_var)\n",
    "    agg_min['method'] = 'min'\n",
    "    agg_mst = pd.concat([agg_sum, agg_uniq, agg_max, agg_min])\n",
    "    return (agg_mst)\n",
    "\n",
    "def _sig_calc(cdr_rec, key_var, TS_cat, dict_cat,sum_var, cnt_var, stat_var):\n",
    "    cdr_dict = cdr_rec.to_dict(orient='records')\n",
    "    cdr_dict = [dict(list(x.items()) + [('TS', '~'.join(list(Discretization(x, TS_cat).values())[0]))] + [\n",
    "        ('cat_str', cat_str(x, dict_cat))]) for x in cdr_dict]\n",
    "    cdr_rec = pd.DataFrame(cdr_dict).reset_index()\n",
    "    # one to many\n",
    "    cat_driver = pd.concat([pd.Series(row['index'], row['cat_str'].split(';'))\n",
    "                            for _, row in cdr_rec.iterrows()]).reset_index()\n",
    "    cat_driver.columns = ['cat', 'index']\n",
    "    cdr_rec_m = pd.merge(cdr_rec, cat_driver, on='index', how='inner')\n",
    "    # Aggregation\n",
    "    if key_var=='':\n",
    "        key_var_tmp = ['TS']\n",
    "    else:\n",
    "        key_var_tmp = key_var+['TS']\n",
    "    agg_mst_m = _agg_df(cdr_rec_m, key_var_tmp+['cat'], sum_var, cnt_var, stat_var)\n",
    "    agg_mst_m['var_name'] = agg_mst_m[['method', 'variable', 'cat']].apply(\n",
    "        lambda x: x[0] + '_' + x[1] + '_cat_' + str(x[2]), axis=1)\n",
    "    if key_var=='':\n",
    "        agg_mst_m['key'] = agg_mst_m[key_var_tmp]\n",
    "    else:\n",
    "        agg_mst_m['key'] = agg_mst_m[key_var_tmp].apply(lambda x: '{0}:{1}'.format(x[0], x[1]), axis=1)\n",
    "    agg_df_m = agg_mst_m.pivot(index='key', columns='var_name', values='value').reset_index()\n",
    "\n",
    "    agg_mst = _agg_df(cdr_rec, key_var_tmp, sum_var, cnt_var, stat_var)\n",
    "    agg_mst['var_name'] = agg_mst[['method', 'variable']].apply(lambda x: x[0] + '_' + x[1] + '_cat_total_all', axis=1)\n",
    "    if key_var=='':\n",
    "        agg_mst['key'] = agg_mst[key_var_tmp]\n",
    "    else:\n",
    "        agg_mst['key'] = agg_mst[key_var_tmp].apply(lambda x: '{0}:{1}'.format(x[0], x[1]), axis=1)\n",
    "    agg_df = agg_mst.pivot(index='key', columns='var_name', values='value').reset_index()\n",
    "\n",
    "    agg_df = pd.merge(agg_df, agg_df_m, on='key', how='left')\n",
    "    \n",
    "    sig_ratio = [sig for sig in agg_df.columns if\n",
    "                 (('sum_' in sig) or ('cnt_' in sig)) and ('cat_total_all' not in sig)]\n",
    "    for sig in sig_ratio:\n",
    "        agg_df['rto_' + sig] = agg_df[[sig, sig.split('cat')[0] + 'cat_total_all']].apply(\n",
    "            lambda x: (x[0] + 0.0) / x[1], axis=1)\n",
    "        del agg_df[sig]\n",
    "    return agg_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _offline_feat(df,key_var='user_id',stat_var=[],part_var=[],mean_var=[],train_feat_col=None):\n",
    "    if not isinstance(key_var,list):\n",
    "        key_var = [key_var]\n",
    "    left_key = key_var.copy()\n",
    "    base_name = '~'.join(key_var)\n",
    "    if train_feat_col:\n",
    "        key_var.append(train_feat_col[1])\n",
    "        left_key.append(train_feat_col[0])\n",
    "        \n",
    "    \n",
    "    df = df.merge(df.groupby(key_var,as_index=False)['instance_id'].agg({base_name+'_cnt':'count'}).rename(columns={train_feat_col[1]:train_feat_col[0]}),'left',left_key)\n",
    "    df = df.merge(df.groupby(key_var,as_index=False)['is_trade'].agg({base_name+'_trade_cnt':'sum',base_name+'_trade_ratio':'mean'}).rename(columns={train_feat_col[1]:train_feat_col[0]}),'left',left_key)\n",
    "    df[base_name+'_notrade_cnt'] = df[base_name+'_cnt']-df[base_name+'_trade_cnt']\n",
    "    dfTmp = df.loc[df['is_trade']==1]\n",
    "    for stat in stat_var:\n",
    "        df = df.merge(df.groupby(key_var,as_index=False)[stat].agg({base_name+'_'+stat+'_min':'min',base_name+'_'+stat+'_max':'max'}).rename(columns={train_feat_col[1]:train_feat_col[0]}),'left',left_key)    \n",
    "    for part in part_var:\n",
    "        df = df.merge(df.groupby(key_var,as_index=False)[part].agg({base_name+'_'+part+'_cnt':'nunique'}).rename(columns={train_feat_col[1]:train_feat_col[0]}),'left',left_key)\n",
    "        df = df.merge(dfTmp.groupby(key_var,as_index=False)[part].agg({base_name+'_'+part+'_trade_cnt':'nunique'}).rename(columns={train_feat_col[1]:train_feat_col[0]}),'left',left_key)\n",
    "        df[base_name+'_'+part+'_trade_cnt'].fillna(0,inplace=True)\n",
    "        df[base_name+'_'+part+'_trade_ratio'] = 1.0*df[base_name+'_'+part+'_trade_cnt']/df[base_name+'_'+part+'_cnt']\n",
    "    for var in mean_var:\n",
    "        df = df.merge(df.groupby(key_var+[var],as_index=False)['is_trade'].sum().groupby(key_var,as_index=False)['is_trade'].agg({base_name+'_'+var+'_avg_trade':'mean'}).rename(columns={train_feat_col[1]:train_feat_col[0]}),'left',left_key)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def map_col(df,drop=False):\n",
    "    map_dict = {\n",
    "        'item_price_level':[4,5,6,7,8,9],\n",
    "        'item_sales_level':[4,6,9,10,11,12,13,14,16],\n",
    "        'item_pv_level':[6,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "        'user_age_level':[1001,1002,1003,1004,1005],\n",
    "        'context_page_id':[4001,4002,4004,4006,4008,4010,4013,4016,4018],\n",
    "        'shop_review_num_level':[5,9,14,15,16,17,18,20,21],\n",
    "        'hour':[6,9,12,17,20],\n",
    "        'user_occupation_id':{-1:2003},\n",
    "        'user_star_level':{-1:3000}\n",
    "    }\n",
    "    for key,value in map_dict.items():\n",
    "        if isinstance(value,list):\n",
    "            df[key+'_mapped'] = 0\n",
    "            for i in range(len(value)):\n",
    "                df.loc[df[key]>value[i],key+'_mapped'] = i+1\n",
    "        else:\n",
    "            '''df[key+'_mapped'] = df[key]\n",
    "            for key_sub,value_sub in value.items():\n",
    "                df.loc[df[key]==key_sub,key+'_mapped'] = value_sub'''\n",
    "            df[key+'_mapped'] = df[key].apply(lambda x:value.get(x,x))\n",
    "        if drop:\n",
    "            df[key] = df[key+'_mapped']\n",
    "            del df[key+'_mapped']\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return list(chain.from_iterable(combinations(s, r) for r in range(len(s)+1)))\n",
    "\n",
    "\n",
    "def cross_feat_plus(df,base_list,order=2):\n",
    "    if order<2:\n",
    "        return df\n",
    "    subset = powerset(base_list)\n",
    "    subset = [i for i in subset if len(i)==order]\n",
    "    for sub in subset:\n",
    "        sub = list(sub)\n",
    "        baseName = '~'.join(sub)+'_plus'\n",
    "        df[baseName] = df[sub].sum(axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def interaction_ratio(df,base_list=[],cal_list=[],rank_list = []):\n",
    "    for base_var in base_list:\n",
    "        if not isinstance(base_var,list):\n",
    "            base_var = [base_var]\n",
    "        if not '_'.join(base_var)+'_cnt' in df.columns:\n",
    "            df = df.merge(df.groupby(base_var,as_index=False)['instance_id'].agg({'_'.join(base_var)+'_cnt':'count'}),'left',base_var)\n",
    "        print('ratio part')\n",
    "        for cal_var in cal_list:\n",
    "            if not isinstance(cal_var,list):\n",
    "                cal_var = [cal_var]\n",
    "            if cal_var==base_var or base_var==['cnt_rec']:\n",
    "                continue\n",
    "            nameBase = '_'.join(base_var)+'~'+'_'.join(cal_var)\n",
    "            print(nameBase)\n",
    "            df = df.merge(df.groupby(base_var+cal_var,as_index=False)['instance_id'].agg({nameBase+'_cnt':'count'}),'left',base_var+cal_var)\n",
    "            df[nameBase+'_ratio'] = df[nameBase+'_cnt']*1.0/df['_'.join(base_var)+'_cnt']\n",
    "            del df[nameBase+'_cnt']\n",
    "        \n",
    "        print('rank part')\n",
    "        for rank_var in rank_list:\n",
    "            if not isinstance(rank_var,list):\n",
    "                rank_var = [rank_var]\n",
    "            if rank_var==base_var:\n",
    "                continue\n",
    "            nameBase = '_'.join(base_var)+'~'+'_'.join(rank_var)\n",
    "            print(nameBase)\n",
    "            df[nameBase+'_rank'] = dfAll.groupby(base_var)[rank_var].rank(method='min')\n",
    "            df[nameBase+'_rank_ratio'] = df[nameBase+'_rank']*1.0/df['_'.join(base_var)+'_cnt']\n",
    "            del df[nameBase+'_rank']\n",
    "        del df['_'.join(base_var)+'_cnt']\n",
    "    return df\n",
    "            \n",
    "def ks_metric(true,score):\n",
    "    fpr, tpr, thresholds = roc_curve(true,score)\n",
    "    ks = max(tpr-fpr)\n",
    "    return ks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#0099ff size=5 face=\"黑体\">读取数据</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496482, 45)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain = pd.read_table(config.TRAIN_FILE,sep=' ')\n",
    "dfTrain.drop_duplicates(inplace=True)\n",
    "dfTrain.reset_index(inplace=True,drop =True)\n",
    "dfTest = pd.read_table(config.TEST_FILE,sep=' ')\n",
    "\n",
    "dfTrain = process(dfTrain)\n",
    "dfTest = process(dfTest)\n",
    "\n",
    "dfAll = pd.concat([dfTrain,dfTest],axis=0)\n",
    "dfAll.reset_index(inplace=True,drop=True)\n",
    "trainNum = dfTrain.shape[0]\n",
    "dfAll['cnt_rec'] = 1\n",
    "dfAll = labelencoder(dfAll)\n",
    "dfAll.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#0099ff size=5 face=\"黑体\">特征工程</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(496482, 45)\n"
     ]
    }
   ],
   "source": [
    "###单特征map\n",
    "dfAll = map_col(dfAll,True)\n",
    "print(dfAll.shape)\n",
    "featBase = [i for i in dfAll.columns.tolist() if not i in config.IGNORE_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(496482, 170)\n"
     ]
    }
   ],
   "source": [
    "###线下特征集合\n",
    "dfAll['feat_set'] = dfAll['day'] + 1\n",
    "keyList = ['user_id','shop_id','item_id','hour']\n",
    "partList = [\n",
    "    ['item_id','shop_id'],\n",
    "    ['user_id','item_id'],\n",
    "    ['user_id','shop_id'],\n",
    "    ['user_id','item_id','shop_id']\n",
    "]\n",
    "meanList = [\n",
    "    ['shop_id'],\n",
    "    ['item_id'],\n",
    "    [],\n",
    "    []\n",
    "]\n",
    "for i in range(len(keyList)):\n",
    "    keyVar = keyList[i]\n",
    "    partVar = partList[i]\n",
    "    meanVar = meanList[i]\n",
    "    statVar = []\n",
    "    if isinstance(keyVar,str):\n",
    "        for key,value in config.STAT_DICT.items():\n",
    "            if key==keyVar:\n",
    "                continue\n",
    "            statVar += value\n",
    "    dfAll = _offline_feat(dfAll,keyVar,statVar,partVar,meanVar,['day','feat_set'])\n",
    "del dfAll['feat_set']\n",
    "print(dfAll.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(496482, 335)\n"
     ]
    }
   ],
   "source": [
    "###连续型变量交叉特征\n",
    "conList = [\n",
    "    'user_gender_id','user_age_level', 'user_star_level',\n",
    "    'item_price_level', 'item_sales_level','item_collected_level', 'item_pv_level',\n",
    "    'context_page_id',\n",
    "    'shop_review_num_level','shop_star_level'\n",
    "]\n",
    "dfAll = cross_feat_plus(dfAll,conList,order=2)\n",
    "dfAll = cross_feat_plus(dfAll,conList,order=3)\n",
    "print(dfAll.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(496482, 338)\n"
     ]
    }
   ],
   "source": [
    "###当天信息的trick\n",
    "keyList = ['user_id']\n",
    "#,'shop_id','item_id','item_city_id','item_brand_id'\n",
    "for keyVar in keyList:\n",
    "    '''timeDiff = False if keyVar=='user_id' else True\n",
    "    dfAll = focus_one_record(dfAll,keyVar,timeDiff)'''\n",
    "    dfAll = same_day_trick(dfAll,keyVar)\n",
    "print(dfAll.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(496482, 618)\n"
     ]
    }
   ],
   "source": [
    "###两两类别变量的比例/rank 顺序\n",
    "'''baseList = [\n",
    "    'cnt_rec',\n",
    "    'user_id','user_gender_id', 'user_occupation_id','user_age_level', 'user_star_level',\n",
    "    'item_id', 'item_brand_id', 'item_city_id', 'item_price_level', 'item_sales_level','item_collected_level', 'item_pv_level',\n",
    "    'item_category_list_bin1','item_category_list_bin2',\n",
    "    'shop_id', 'shop_review_num_level','shop_star_level'\n",
    "    \n",
    "]\n",
    "\n",
    "calList = [\n",
    "    'user_id','user_gender_id', 'user_occupation_id','item_id', 'item_brand_id', 'item_city_id',\n",
    "    'item_category_list_bin1','item_category_list_bin2','shop_id'\n",
    "]\n",
    "rankList = [\n",
    "    'user_age_level', 'user_star_level','item_price_level', 'item_sales_level','item_collected_level', 'item_pv_level','shop_review_num_level','shop_star_level'\n",
    "]\n",
    "\n",
    "dfAll = interaction_ratio(dfAll,baseList,calList,rankList)'''\n",
    "dfCross = pd.read_csv('../../Data/advertisment/Cache/ratio_rank.csv')\n",
    "dfAll = pd.concat([dfAll,dfCross],axis=1)\n",
    "\n",
    "print(dfAll.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###变量的多组合\n",
    "featCorr = dfAll[featBase].corr('spearman')\n",
    "for i in range(len(featBase)-1):\n",
    "    for j in range(i+1,len(featBase)):\n",
    "        try: tmpBound = featCorr.loc[featBase[i],featBase[j]]\n",
    "        except: continue\n",
    "        if abs(tmpBound)>=0.5:\n",
    "            continue\n",
    "        baseName = '~'.join([featBase[i],featBase[j]])+'_com'\n",
    "        dfAll[baseName] = dfAll[[featBase[i],featBase[j]]].apply(lambda x: str(x[0])+'_'+str(x[1]),axis=1)\n",
    "print(dfAll.shape)\n",
    "\n",
    "#dfAll.to_csv(\"../../Data/advertisment/Cache/All_multi_combination.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [i for i in dfAll.columns.tolist() if not i in config.IGNORE_COLS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#0099ff size=5 face=\"黑体\">拆分样本</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_idx = dfTrain.loc[(dfTrain['day']<24)&(dfTrain['day']>18)].index\n",
    "valid_idx = dfTrain.loc[dfTrain['day']==24].index\n",
    "Xi_train_, y_train_ = dfAll.loc[list(train_idx),features],dfTrain.loc[train_idx,'is_trade']\n",
    "Xi_valid_, y_valid_ = dfAll.loc[list(valid_idx),features],dfTrain.loc[valid_idx,'is_trade']\n",
    "Xi_test_ = dfAll.loc[trainNum:,features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.85998450e-02,   0.00000000e+00,   1.11111111e-01, ...,\n",
       "          1.00000000e+00,   3.87366681e-05,   9.96667521e-01],\n",
       "       [  1.31587965e-02,   1.00000000e+00,   1.11111111e-01, ...,\n",
       "          1.30000000e+01,   1.80771118e-04,   9.93964585e-01],\n",
       "       [  1.31587965e-02,   1.00000000e+00,   5.00000000e-01, ...,\n",
       "          7.00000000e+00,   1.80771118e-04,   9.93964585e-01],\n",
       "       ..., \n",
       "       [  1.55869830e-02,   0.00000000e+00,   5.00000000e-01, ...,\n",
       "          7.00000000e+00,   9.03855590e-05,   9.95956558e-01],\n",
       "       [  1.55869830e-02,   1.00000000e+00,   7.69230769e-02, ...,\n",
       "          7.00000000e+00,   9.03855590e-05,   9.95956558e-01],\n",
       "       [  1.55869830e-02,   1.00000000e+00,   2.50000000e-01, ...,\n",
       "          6.00000000e+00,   1.42773518e-05,   9.96667521e-01]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xi_finnal_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#0099ff size=5 face=\"黑体\">模型</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo Mao\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['item_category_list_bin1']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.647706\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[2]\tvalid_0's binary_logloss: 0.606567\n",
      "[3]\tvalid_0's binary_logloss: 0.569201\n",
      "[4]\tvalid_0's binary_logloss: 0.535111\n",
      "[5]\tvalid_0's binary_logloss: 0.503908\n",
      "[6]\tvalid_0's binary_logloss: 0.475261\n",
      "[7]\tvalid_0's binary_logloss: 0.448908\n",
      "[8]\tvalid_0's binary_logloss: 0.424573\n",
      "[9]\tvalid_0's binary_logloss: 0.402108\n",
      "[10]\tvalid_0's binary_logloss: 0.381229\n",
      "[11]\tvalid_0's binary_logloss: 0.361898\n",
      "[12]\tvalid_0's binary_logloss: 0.343942\n",
      "[13]\tvalid_0's binary_logloss: 0.327239\n",
      "[14]\tvalid_0's binary_logloss: 0.311633\n",
      "[15]\tvalid_0's binary_logloss: 0.29715\n",
      "[16]\tvalid_0's binary_logloss: 0.283635\n",
      "[17]\tvalid_0's binary_logloss: 0.271004\n",
      "[18]\tvalid_0's binary_logloss: 0.259149\n",
      "[19]\tvalid_0's binary_logloss: 0.248103\n",
      "[20]\tvalid_0's binary_logloss: 0.237771\n",
      "[21]\tvalid_0's binary_logloss: 0.228084\n",
      "[22]\tvalid_0's binary_logloss: 0.219021\n",
      "[23]\tvalid_0's binary_logloss: 0.210531\n",
      "[24]\tvalid_0's binary_logloss: 0.20256\n",
      "[25]\tvalid_0's binary_logloss: 0.195088\n",
      "[26]\tvalid_0's binary_logloss: 0.188055\n",
      "[27]\tvalid_0's binary_logloss: 0.181447\n",
      "[28]\tvalid_0's binary_logloss: 0.175261\n",
      "[29]\tvalid_0's binary_logloss: 0.169443\n",
      "[30]\tvalid_0's binary_logloss: 0.163982\n",
      "[31]\tvalid_0's binary_logloss: 0.158835\n",
      "[32]\tvalid_0's binary_logloss: 0.154011\n",
      "[33]\tvalid_0's binary_logloss: 0.14948\n",
      "[34]\tvalid_0's binary_logloss: 0.145189\n",
      "[35]\tvalid_0's binary_logloss: 0.141174\n",
      "[36]\tvalid_0's binary_logloss: 0.137414\n",
      "[37]\tvalid_0's binary_logloss: 0.133868\n",
      "[38]\tvalid_0's binary_logloss: 0.130535\n",
      "[39]\tvalid_0's binary_logloss: 0.127406\n",
      "[40]\tvalid_0's binary_logloss: 0.124445\n",
      "[41]\tvalid_0's binary_logloss: 0.121692\n",
      "[42]\tvalid_0's binary_logloss: 0.119073\n",
      "[43]\tvalid_0's binary_logloss: 0.116639\n",
      "[44]\tvalid_0's binary_logloss: 0.114324\n",
      "[45]\tvalid_0's binary_logloss: 0.112173\n",
      "[46]\tvalid_0's binary_logloss: 0.110125\n",
      "[47]\tvalid_0's binary_logloss: 0.108227\n",
      "[48]\tvalid_0's binary_logloss: 0.106441\n",
      "[49]\tvalid_0's binary_logloss: 0.104749\n",
      "[50]\tvalid_0's binary_logloss: 0.10318\n",
      "[51]\tvalid_0's binary_logloss: 0.101706\n",
      "[52]\tvalid_0's binary_logloss: 0.100338\n",
      "[53]\tvalid_0's binary_logloss: 0.0990239\n",
      "[54]\tvalid_0's binary_logloss: 0.0978081\n",
      "[55]\tvalid_0's binary_logloss: 0.0966762\n",
      "[56]\tvalid_0's binary_logloss: 0.095605\n",
      "[57]\tvalid_0's binary_logloss: 0.0945873\n",
      "[58]\tvalid_0's binary_logloss: 0.0936368\n",
      "[59]\tvalid_0's binary_logloss: 0.0927577\n",
      "[60]\tvalid_0's binary_logloss: 0.0919226\n",
      "[61]\tvalid_0's binary_logloss: 0.0911515\n",
      "[62]\tvalid_0's binary_logloss: 0.0904378\n",
      "[63]\tvalid_0's binary_logloss: 0.0897531\n",
      "[64]\tvalid_0's binary_logloss: 0.0891077\n",
      "[65]\tvalid_0's binary_logloss: 0.0884856\n",
      "[66]\tvalid_0's binary_logloss: 0.0879318\n",
      "[67]\tvalid_0's binary_logloss: 0.0874048\n",
      "[68]\tvalid_0's binary_logloss: 0.0869292\n",
      "[69]\tvalid_0's binary_logloss: 0.0864738\n",
      "[70]\tvalid_0's binary_logloss: 0.0860328\n",
      "[71]\tvalid_0's binary_logloss: 0.0856175\n",
      "[72]\tvalid_0's binary_logloss: 0.0852276\n",
      "[73]\tvalid_0's binary_logloss: 0.0848748\n",
      "[74]\tvalid_0's binary_logloss: 0.0845413\n",
      "[75]\tvalid_0's binary_logloss: 0.0842436\n",
      "[76]\tvalid_0's binary_logloss: 0.0839586\n",
      "[77]\tvalid_0's binary_logloss: 0.0836915\n",
      "[78]\tvalid_0's binary_logloss: 0.0834532\n",
      "[79]\tvalid_0's binary_logloss: 0.0832153\n",
      "[80]\tvalid_0's binary_logloss: 0.0829976\n",
      "[81]\tvalid_0's binary_logloss: 0.0827792\n",
      "[82]\tvalid_0's binary_logloss: 0.0825891\n",
      "[83]\tvalid_0's binary_logloss: 0.0824229\n",
      "[84]\tvalid_0's binary_logloss: 0.0822566\n",
      "[85]\tvalid_0's binary_logloss: 0.0820961\n",
      "[86]\tvalid_0's binary_logloss: 0.0819438\n",
      "[87]\tvalid_0's binary_logloss: 0.0817962\n",
      "[88]\tvalid_0's binary_logloss: 0.0816705\n",
      "[89]\tvalid_0's binary_logloss: 0.0815611\n",
      "[90]\tvalid_0's binary_logloss: 0.0814501\n",
      "[91]\tvalid_0's binary_logloss: 0.081355\n",
      "[92]\tvalid_0's binary_logloss: 0.0812543\n",
      "[93]\tvalid_0's binary_logloss: 0.0811678\n",
      "[94]\tvalid_0's binary_logloss: 0.0810801\n",
      "[95]\tvalid_0's binary_logloss: 0.0809862\n",
      "[96]\tvalid_0's binary_logloss: 0.0809265\n",
      "[97]\tvalid_0's binary_logloss: 0.0808671\n",
      "[98]\tvalid_0's binary_logloss: 0.0807936\n",
      "[99]\tvalid_0's binary_logloss: 0.0807241\n",
      "[100]\tvalid_0's binary_logloss: 0.0806667\n",
      "[101]\tvalid_0's binary_logloss: 0.08061\n",
      "[102]\tvalid_0's binary_logloss: 0.0805729\n",
      "[103]\tvalid_0's binary_logloss: 0.0805303\n",
      "[104]\tvalid_0's binary_logloss: 0.080495\n",
      "[105]\tvalid_0's binary_logloss: 0.0804559\n",
      "[106]\tvalid_0's binary_logloss: 0.0803992\n",
      "[107]\tvalid_0's binary_logloss: 0.0803356\n",
      "[108]\tvalid_0's binary_logloss: 0.0803006\n",
      "[109]\tvalid_0's binary_logloss: 0.0802667\n",
      "[110]\tvalid_0's binary_logloss: 0.0802376\n",
      "[111]\tvalid_0's binary_logloss: 0.0801707\n",
      "[112]\tvalid_0's binary_logloss: 0.0801432\n",
      "[113]\tvalid_0's binary_logloss: 0.0801153\n",
      "[114]\tvalid_0's binary_logloss: 0.0800918\n",
      "[115]\tvalid_0's binary_logloss: 0.0800546\n",
      "[116]\tvalid_0's binary_logloss: 0.0800315\n",
      "[117]\tvalid_0's binary_logloss: 0.0799935\n",
      "[118]\tvalid_0's binary_logloss: 0.079979\n",
      "[119]\tvalid_0's binary_logloss: 0.0799421\n",
      "[120]\tvalid_0's binary_logloss: 0.0799254\n",
      "[121]\tvalid_0's binary_logloss: 0.0798986\n",
      "[122]\tvalid_0's binary_logloss: 0.0798789\n",
      "[123]\tvalid_0's binary_logloss: 0.0798526\n",
      "[124]\tvalid_0's binary_logloss: 0.0798414\n",
      "[125]\tvalid_0's binary_logloss: 0.0798421\n",
      "[126]\tvalid_0's binary_logloss: 0.0797952\n",
      "[127]\tvalid_0's binary_logloss: 0.0797696\n",
      "[128]\tvalid_0's binary_logloss: 0.0797568\n",
      "[129]\tvalid_0's binary_logloss: 0.0797438\n",
      "[130]\tvalid_0's binary_logloss: 0.0797314\n",
      "[131]\tvalid_0's binary_logloss: 0.0797298\n",
      "[132]\tvalid_0's binary_logloss: 0.0797239\n",
      "[133]\tvalid_0's binary_logloss: 0.079734\n",
      "[134]\tvalid_0's binary_logloss: 0.0797212\n",
      "[135]\tvalid_0's binary_logloss: 0.0797072\n",
      "[136]\tvalid_0's binary_logloss: 0.0797156\n",
      "[137]\tvalid_0's binary_logloss: 0.0797195\n",
      "[138]\tvalid_0's binary_logloss: 0.0797085\n",
      "[139]\tvalid_0's binary_logloss: 0.0797079\n",
      "[140]\tvalid_0's binary_logloss: 0.0797003\n",
      "[141]\tvalid_0's binary_logloss: 0.0796891\n",
      "[142]\tvalid_0's binary_logloss: 0.0796735\n",
      "[143]\tvalid_0's binary_logloss: 0.0796666\n",
      "[144]\tvalid_0's binary_logloss: 0.079657\n",
      "[145]\tvalid_0's binary_logloss: 0.0796629\n",
      "[146]\tvalid_0's binary_logloss: 0.0796536\n",
      "[147]\tvalid_0's binary_logloss: 0.0796451\n",
      "[148]\tvalid_0's binary_logloss: 0.0796592\n",
      "[149]\tvalid_0's binary_logloss: 0.0796651\n",
      "[150]\tvalid_0's binary_logloss: 0.0796373\n",
      "[151]\tvalid_0's binary_logloss: 0.0796419\n",
      "[152]\tvalid_0's binary_logloss: 0.0796517\n",
      "[153]\tvalid_0's binary_logloss: 0.0796318\n",
      "[154]\tvalid_0's binary_logloss: 0.0796409\n",
      "[155]\tvalid_0's binary_logloss: 0.079646\n",
      "[156]\tvalid_0's binary_logloss: 0.0796541\n",
      "[157]\tvalid_0's binary_logloss: 0.0796487\n",
      "[158]\tvalid_0's binary_logloss: 0.0796495\n",
      "[159]\tvalid_0's binary_logloss: 0.0796401\n",
      "[160]\tvalid_0's binary_logloss: 0.0796316\n",
      "[161]\tvalid_0's binary_logloss: 0.0796386\n",
      "[162]\tvalid_0's binary_logloss: 0.0796413\n",
      "[163]\tvalid_0's binary_logloss: 0.0796508\n",
      "[164]\tvalid_0's binary_logloss: 0.0796585\n",
      "[165]\tvalid_0's binary_logloss: 0.0796571\n",
      "[166]\tvalid_0's binary_logloss: 0.0796464\n",
      "[167]\tvalid_0's binary_logloss: 0.0796465\n",
      "[168]\tvalid_0's binary_logloss: 0.0796415\n",
      "[169]\tvalid_0's binary_logloss: 0.0796262\n",
      "[170]\tvalid_0's binary_logloss: 0.079631\n",
      "[171]\tvalid_0's binary_logloss: 0.0796342\n",
      "[172]\tvalid_0's binary_logloss: 0.0796404\n",
      "[173]\tvalid_0's binary_logloss: 0.0796468\n",
      "[174]\tvalid_0's binary_logloss: 0.0796645\n",
      "[175]\tvalid_0's binary_logloss: 0.0796601\n",
      "[176]\tvalid_0's binary_logloss: 0.0796668\n",
      "[177]\tvalid_0's binary_logloss: 0.0796654\n",
      "[178]\tvalid_0's binary_logloss: 0.0796704\n",
      "[179]\tvalid_0's binary_logloss: 0.0796806\n",
      "[180]\tvalid_0's binary_logloss: 0.0796828\n",
      "[181]\tvalid_0's binary_logloss: 0.0796764\n",
      "[182]\tvalid_0's binary_logloss: 0.0796865\n",
      "[183]\tvalid_0's binary_logloss: 0.0796804\n",
      "[184]\tvalid_0's binary_logloss: 0.0796805\n",
      "[185]\tvalid_0's binary_logloss: 0.0796787\n",
      "[186]\tvalid_0's binary_logloss: 0.0796773\n",
      "[187]\tvalid_0's binary_logloss: 0.0796763\n",
      "[188]\tvalid_0's binary_logloss: 0.0796675\n",
      "[189]\tvalid_0's binary_logloss: 0.0796682\n",
      "[190]\tvalid_0's binary_logloss: 0.0796689\n",
      "[191]\tvalid_0's binary_logloss: 0.0796816\n",
      "[192]\tvalid_0's binary_logloss: 0.0796778\n",
      "[193]\tvalid_0's binary_logloss: 0.0796791\n",
      "[194]\tvalid_0's binary_logloss: 0.0796911\n",
      "[195]\tvalid_0's binary_logloss: 0.0796887\n",
      "[196]\tvalid_0's binary_logloss: 0.0796863\n",
      "[197]\tvalid_0's binary_logloss: 0.0796954\n",
      "[198]\tvalid_0's binary_logloss: 0.0797019\n",
      "[199]\tvalid_0's binary_logloss: 0.0797047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's binary_logloss: 0.0797277\n",
      "[201]\tvalid_0's binary_logloss: 0.0797363\n",
      "[202]\tvalid_0's binary_logloss: 0.0797318\n",
      "[203]\tvalid_0's binary_logloss: 0.0797303\n",
      "[204]\tvalid_0's binary_logloss: 0.0797307\n",
      "[205]\tvalid_0's binary_logloss: 0.0797217\n",
      "[206]\tvalid_0's binary_logloss: 0.0797203\n",
      "[207]\tvalid_0's binary_logloss: 0.0797205\n",
      "[208]\tvalid_0's binary_logloss: 0.0797294\n",
      "[209]\tvalid_0's binary_logloss: 0.0797361\n",
      "[210]\tvalid_0's binary_logloss: 0.0797354\n",
      "[211]\tvalid_0's binary_logloss: 0.0797432\n",
      "[212]\tvalid_0's binary_logloss: 0.0797411\n",
      "[213]\tvalid_0's binary_logloss: 0.0797447\n",
      "[214]\tvalid_0's binary_logloss: 0.0797453\n",
      "[215]\tvalid_0's binary_logloss: 0.0797431\n",
      "[216]\tvalid_0's binary_logloss: 0.0797397\n",
      "[217]\tvalid_0's binary_logloss: 0.0797401\n",
      "[218]\tvalid_0's binary_logloss: 0.0797478\n",
      "[219]\tvalid_0's binary_logloss: 0.0797351\n",
      "[220]\tvalid_0's binary_logloss: 0.0797413\n",
      "[221]\tvalid_0's binary_logloss: 0.0797419\n",
      "[222]\tvalid_0's binary_logloss: 0.079744\n",
      "[223]\tvalid_0's binary_logloss: 0.0797427\n",
      "[224]\tvalid_0's binary_logloss: 0.0797636\n",
      "[225]\tvalid_0's binary_logloss: 0.0797662\n",
      "[226]\tvalid_0's binary_logloss: 0.0797716\n",
      "[227]\tvalid_0's binary_logloss: 0.0797748\n",
      "[228]\tvalid_0's binary_logloss: 0.0797787\n",
      "[229]\tvalid_0's binary_logloss: 0.0797788\n",
      "[230]\tvalid_0's binary_logloss: 0.079778\n",
      "[231]\tvalid_0's binary_logloss: 0.079791\n",
      "[232]\tvalid_0's binary_logloss: 0.0797959\n",
      "[233]\tvalid_0's binary_logloss: 0.0797911\n",
      "[234]\tvalid_0's binary_logloss: 0.0797918\n",
      "[235]\tvalid_0's binary_logloss: 0.0797983\n",
      "[236]\tvalid_0's binary_logloss: 0.0797941\n",
      "[237]\tvalid_0's binary_logloss: 0.0797948\n",
      "[238]\tvalid_0's binary_logloss: 0.0797816\n",
      "[239]\tvalid_0's binary_logloss: 0.079782\n",
      "[240]\tvalid_0's binary_logloss: 0.0797925\n",
      "[241]\tvalid_0's binary_logloss: 0.0797971\n",
      "[242]\tvalid_0's binary_logloss: 0.0797971\n",
      "[243]\tvalid_0's binary_logloss: 0.0797862\n",
      "[244]\tvalid_0's binary_logloss: 0.0797995\n",
      "[245]\tvalid_0's binary_logloss: 0.0798079\n",
      "[246]\tvalid_0's binary_logloss: 0.079814\n",
      "[247]\tvalid_0's binary_logloss: 0.0798236\n",
      "[248]\tvalid_0's binary_logloss: 0.0798232\n",
      "[249]\tvalid_0's binary_logloss: 0.0798248\n",
      "[250]\tvalid_0's binary_logloss: 0.0798237\n",
      "[251]\tvalid_0's binary_logloss: 0.0798318\n",
      "[252]\tvalid_0's binary_logloss: 0.0798216\n",
      "[253]\tvalid_0's binary_logloss: 0.0798241\n",
      "[254]\tvalid_0's binary_logloss: 0.0798134\n",
      "[255]\tvalid_0's binary_logloss: 0.0798073\n",
      "[256]\tvalid_0's binary_logloss: 0.0798159\n",
      "[257]\tvalid_0's binary_logloss: 0.0798166\n",
      "[258]\tvalid_0's binary_logloss: 0.0798119\n",
      "[259]\tvalid_0's binary_logloss: 0.0798045\n",
      "[260]\tvalid_0's binary_logloss: 0.0798042\n",
      "[261]\tvalid_0's binary_logloss: 0.0798062\n",
      "[262]\tvalid_0's binary_logloss: 0.0797978\n",
      "[263]\tvalid_0's binary_logloss: 0.0797918\n",
      "[264]\tvalid_0's binary_logloss: 0.0797967\n",
      "[265]\tvalid_0's binary_logloss: 0.0797901\n",
      "[266]\tvalid_0's binary_logloss: 0.0797719\n",
      "[267]\tvalid_0's binary_logloss: 0.0797707\n",
      "[268]\tvalid_0's binary_logloss: 0.0797525\n",
      "[269]\tvalid_0's binary_logloss: 0.0797525\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's binary_logloss: 0.0796262\n",
      "                                                 index    0\n",
      "0                                     hour_trade_ratio  139\n",
      "1     item_collected_level~item_sales_level_rank_ratio  129\n",
      "2                                 user_id_before_exist  112\n",
      "3                                user_id~item_id_ratio   97\n",
      "4           user_age_level~item_price_level_rank_ratio   90\n",
      "5                      item_id_shop_score_delivery_min   86\n",
      "6                                  user_id_after_exist   85\n",
      "7            item_pv_level~item_sales_level_rank_ratio   83\n",
      "8                                  shop_score_delivery   78\n",
      "9                          shop_id_user_id_trade_ratio   78\n",
      "10                          user_id~item_city_id_ratio   74\n",
      "11                               user_id~shop_id_ratio   69\n",
      "12   user_age_level~user_star_level~item_sales_leve...   68\n",
      "13                            hour_user_id_trade_ratio   66\n",
      "14           item_sales_level~item_pv_level_rank_ratio   59\n",
      "15                              len_item_property_list   55\n",
      "16                         user_id~item_brand_id_ratio   53\n",
      "17                                 item_id_trade_ratio   52\n",
      "18               user_id~item_category_list_bin1_ratio   52\n",
      "19                                                hour   50\n",
      "20                  shop_id~user_star_level_rank_ratio   49\n",
      "21                       user_star_level~user_id_ratio   48\n",
      "22                         item_id_user_id_trade_ratio   46\n",
      "23                                 shop_id_item_id_cnt   45\n",
      "24                      item_sales_level~user_id_ratio   44\n",
      "25    item_sales_level~item_collected_level_rank_ratio   43\n",
      "26                    user_id~item_pv_level_rank_ratio   40\n",
      "27           item_pv_level~item_price_level_rank_ratio   38\n",
      "28                               shop_id~item_id_ratio   38\n",
      "29                             item_category_list_bin1   36\n",
      "..                                                 ...  ...\n",
      "354  user_gender_id~item_price_level~item_sales_lev...    5\n",
      "355                     item_price_level~shop_id_ratio    5\n",
      "356      shop_star_level~item_category_list_bin2_ratio    5\n",
      "357                       user_id_item_sales_level_min    5\n",
      "358                         predict_category_property9    4\n",
      "359        user_occupation_id~item_pv_level_rank_ratio    4\n",
      "360          item_sales_level~user_occupation_id_ratio    4\n",
      "361  user_gender_id~context_page_id~shop_review_num...    4\n",
      "362  item_price_level~item_sales_level~context_page...    4\n",
      "363    item_collected_level~shop_review_num_level_plus    4\n",
      "364                  user_age_level~item_pv_level_plus    4\n",
      "365                                item_id_notrade_cnt    4\n",
      "366     item_price_level~item_category_list_bin1_ratio    4\n",
      "367               context_page_id~shop_star_level_plus    4\n",
      "368                                       item_city_id    4\n",
      "369  item_category_list_bin1~user_star_level_rank_r...    4\n",
      "370             item_pv_level~user_occupation_id_ratio    4\n",
      "371          shop_review_num_level~item_brand_id_ratio    4\n",
      "372           item_id~shop_review_num_level_rank_ratio    4\n",
      "373         user_star_level~shop_review_num_level_plus    4\n",
      "374                       user_id_item_price_level_min    4\n",
      "375  item_price_level~item_collected_level~context_...    4\n",
      "376        user_star_level~item_sales_level_rank_ratio    3\n",
      "377  item_category_list_bin2~item_category_list_bin...    3\n",
      "378               item_sales_level~item_brand_id_ratio    3\n",
      "379         item_price_level~item_collected_level_plus    3\n",
      "380     item_sales_level~item_category_list_bin2_ratio    3\n",
      "381          user_gender_id~shop_star_level_rank_ratio    2\n",
      "382      user_star_level~item_category_list_bin2_ratio    2\n",
      "383                  user_gender_id~item_city_id_ratio    1\n",
      "\n",
      "[384 rows x 2 columns]\n",
      "0.0796261954311\n",
      "0.334106318032\n"
     ]
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier(\n",
    "    num_leaves=40, \n",
    "    max_depth=8,\n",
    "    n_estimators=20000,\n",
    "    n_jobs=20,\n",
    "    learning_rate=0.05,\n",
    "    colsample_bytree=0.8,\n",
    "    subsample=0.9,\n",
    "    max_bin=20\n",
    ")\n",
    "clf.fit(Xi_train_, y_train_, eval_set=[(Xi_valid_, y_valid_)],\n",
    "        categorical_feature=[i for i in ['item_category_list_bin1','item_category_list_bin2'] if i in features],early_stopping_rounds=100)\n",
    "y_score_ = clf.predict_proba(Xi_valid_,)[:, 1]\n",
    "\n",
    "print(pd.Series(clf.feature_importances_, features).sort_values(ascending=False).reset_index())\n",
    "print(log_loss(y_valid_, y_score_))\n",
    "print(ks_metric(y_valid_, y_score_))\n",
    "bstIter = clf.best_iteration_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xx = pd.Series(clf.feature_importances_, features).sort_values(ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = xx.loc[xx[0]>4,'index'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index    607\n",
       "0        412\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(xx<6).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_change(score,base_rate,real_rate):\n",
    "    base_change = np.log(base_rate/(1-base_rate)) - np.log(real_rate/(1-real_rate))\n",
    "    score_adj = np.exp(np.log(score/(1-score)) - base_change)/(np.exp(np.log(score/(1-score)) - base_change)+1)\n",
    "    return score_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0796956486779\n"
     ]
    }
   ],
   "source": [
    "y_score_adj = score_change(y_score_,y_score_.mean(),y_valid_.mean())\n",
    "print(log_loss(y_valid_, y_score_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo Mao\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['item_category_list_bin1']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    }
   ],
   "source": [
    "#Xi_finnal_ ,y_finnal_ = np.vstack((Xi_train_,Xi_valid_),np.hstack((y_train_,y_valid_))\n",
    "Xi_finnal_ ,y_finnal_ = pd.concat([Xi_train_,Xi_valid_]), pd.concat([y_train_,y_valid_])\n",
    "clf = lgb.LGBMClassifier(\n",
    "    num_leaves=40, \n",
    "    max_depth=8,\n",
    "    n_estimators=bstIter,\n",
    "    n_jobs=20,\n",
    "    learning_rate=0.05,\n",
    "    colsample_bytree=0.8,\n",
    "    subsample=0.9,\n",
    "    max_bin=20\n",
    ")\n",
    "clf.fit(Xi_finnal_, y_finnal_,\n",
    "        categorical_feature=[i for i in ['item_category_list_bin1','item_category_list_bin2'] if i in features])\n",
    "y_test_meta = np.zeros((dfTest.shape[0], 1), dtype=float)\n",
    "y_test_meta[:,0] += clf.predict_proba(Xi_test_)[:,1]\n",
    "submit = pd.DataFrame({'instance_id':dfTest['instance_id'],'predicted_score':y_test_meta[:,0]})\n",
    "#submit.to_csv('../../Submission/advertisement/gbm_trick_0330.txt', sep=\" \", index=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01960302138925454"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['predicted_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../../Submission/advertisement/gbm_trick_411.txt',sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['predicted_score'] = submit['predicted_score'] - submit['predicted_score'].mean() + 0.016983086400719192\n",
    "submit.loc[submit['predicted_score']<0,'predicted_score'] =0\n",
    "submit.to_csv('../../Submission/advertisement/gbm_trick_412_adj_v2.txt', sep=\" \", index=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017020051538291222"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['predicted_score'] = score_change(submit['predicted_score'],submit['predicted_score'].mean(),0.016983086400719192)\n",
    "submit['predicted_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit.to_csv('../../Submission/advertisement/gbm_trick_select_412_adj.txt', sep=\" \", index=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.hstack((y_train_,y_valid_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_meta = np.zeros((dfTest.shape[0], 1), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'instance_id':dfTest['instance_id'],'predicted_score':y_test_meta[:,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit['predicted_score'] = 1.0\n",
    "submit.to_csv('../../Submission/advertisement/test_0330.txt', sep=\" \", index=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "sys.path.append('tools/tensorflow-DeepFM-master/')\n",
    "\n",
    "import config\n",
    "import DataReader\n",
    "from DeepFM import DeepFM\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#0099ff size=5 face=\"黑体\">固定函数</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timestamp_datetime(value):\n",
    "    format = '%Y-%m-%d %H:%M:%S'\n",
    "    value = time.localtime(value)\n",
    "    dt = time.strftime(format, value)\n",
    "    return value.tm_hour\n",
    "\n",
    "def process(df):\n",
    "    cols = [c for c in df.columns if c not in config.KEYS]\n",
    "    df[\"missing_feat\"] = np.sum((df[cols] == -1).values, axis=1)\n",
    "    df['context_timestamp_hour'] = df['context_timestamp'].map(timestamp_datetime)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#0099ff size=5 face=\"黑体\">读取数据</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTrain = pd.read_table(config.TRAIN_FILE,sep=' ')\n",
    "dfTest = pd.read_table(config.TEST_FILE,sep=' ')\n",
    "\n",
    "dfTrain = process(dfTrain)\n",
    "dfTest = process(dfTest)\n",
    "\n",
    "featInput = [c for c in dfTrain.columns if c not in config.KEYS]\n",
    "featInput = [c for c in cols if (not c in config.IGNORE_COLS)]\n",
    "\n",
    "TrainX = dfTrain[featInput].values\n",
    "TestX = dfTest[featInput].values\n",
    "Trainy = dfTrain[config.LABEL].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['item_brand_id', 'item_city_id', 'item_price_level', 'item_sales_level', 'item_collected_level', 'item_pv_level', 'user_gender_id', 'user_age_level', 'user_occupation_id', 'user_star_level', 'context_timestamp', 'context_page_id', 'shop_review_num_level', 'shop_review_positive_rate', 'shop_star_level', 'shop_score_service', 'shop_score_delivery', 'shop_score_description']\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "featInput = []\n",
    "keyList = ['instance_id','item_id','user_id','context_id','shop_id','is_trade']\n",
    "for var in dfTrain.columns:\n",
    "    if not var in keyList and dfTrain[var].dtypes != 'object':\n",
    "        featInput.append(var)\n",
    "print(featInput)\n",
    "print(len(featInput))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance_id False\n",
      "item_id False\n",
      "item_category_list False\n",
      "item_property_list False\n",
      "item_brand_id True\n",
      "item_city_id True\n",
      "item_price_level False\n",
      "item_sales_level True\n",
      "item_collected_level False\n",
      "item_pv_level False\n",
      "user_id False\n",
      "user_gender_id True\n",
      "user_age_level True\n",
      "user_occupation_id True\n",
      "user_star_level True\n",
      "context_id False\n",
      "context_timestamp False\n",
      "context_page_id False\n",
      "predict_category_property False\n",
      "shop_id False\n",
      "shop_review_num_level False\n",
      "shop_review_positive_rate True\n",
      "shop_star_level False\n",
      "shop_score_service True\n",
      "shop_score_delivery True\n",
      "shop_score_description True\n",
      "is_trade False\n"
     ]
    }
   ],
   "source": [
    "for var in dfTrain.columns:\n",
    "    print(var,-1 in dfTrain[var].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTrain['context_timestamp_hour'] = dfTrain['context_timestamp'].map(timestamp_datetime)\n",
    "try: featInput.remove('context_timestamp')\n",
    "except: print('context_timestamp has been deleted')\n",
    "if not 'context_timestamp_hour' in featInput:\n",
    "    featInput.append('context_timestamp_hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummyInput = []\n",
    "removeInput = []\n",
    "for var in featInput:\n",
    "    if 'int' in str(dfTrain[var].dtypes):\n",
    "        print(var)\n",
    "        dfTrain[var].replace({-1:np.nan},inplace=True)\n",
    "        dfTmp = pd.get_dummies(dfTrain[var],var)\n",
    "        dfTrain = pd.concat([dfTrain,dfTmp],axis=1)\n",
    "        try:\n",
    "            removeInput.append(var)\n",
    "            dummyInput +=dfTmp.columns.tolist()\n",
    "        except:\n",
    "            print('Removed')\n",
    "for var in removeInput:\n",
    "    featInput.remove(var)\n",
    "featInput+=dummyInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for trainIndex,testIndex in cv.split(dfTrain[keyList]):\n",
    "    trainX,testX = dfTrain.loc[trainIndex,featInput],dfTrain.loc[testIndex,featInput]\n",
    "    trainY,testY = dfTrain.loc[trainIndex,'is_trade'],dfTrain.loc[testIndex,'is_trade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfm_params = {\n",
    "    \"use_fm\": True,\n",
    "    \"use_deep\": True,\n",
    "    \"embedding_size\": 8,\n",
    "    \"dropout_fm\": [1.0, 1.0],\n",
    "    \"deep_layers\": [32, 32],\n",
    "    \"dropout_deep\": [0.5, 0.5, 0.5],\n",
    "    \"deep_layers_activation\": tf.nn.relu,\n",
    "    \"epoch\": 30,\n",
    "    \"batch_size\": 1024,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer_type\": \"adam\",\n",
    "    \"batch_norm\": 1,\n",
    "    \"batch_norm_decay\": 0.995,\n",
    "    \"l2_reg\": 0.01,\n",
    "    \"verbose\": True,\n",
    "    \"random_seed\": 42\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfm_params[\"feature_size\"] = fd.feat_dim\n",
    "dfm_params[\"field_size\"] = len(Xi_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfm = DeepFM.DeepFM(**dfm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

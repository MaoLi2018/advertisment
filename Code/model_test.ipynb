{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "sys.path.append('tools/')\n",
    "\n",
    "import FM_FTRL_machine\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package tffm:\n",
      "\n",
      "NAME\n",
      "    tffm\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    base\n",
      "    core\n",
      "    models\n",
      "    utils\n",
      "\n",
      "CLASSES\n",
      "    tffm.base.TFFMBaseModel(sklearn.base.BaseEstimator)\n",
      "        tffm.models.TFFMClassifier\n",
      "        tffm.models.TFFMRegressor\n",
      "    \n",
      "    class TFFMClassifier(tffm.base.TFFMBaseModel)\n",
      "     |  Factorization Machine (aka FM).\n",
      "     |  \n",
      "     |  This class implements L2-regularized arbitrary order FM model with logistic\n",
      "     |  loss and gradient-based optimization.\n",
      "     |  \n",
      "     |  Only binary classification with 0/1 labels supported.\n",
      "     |  \n",
      "     |  See TFFMBaseModel and TFFMCore docs for details about parameters.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TFFMClassifier\n",
      "     |      tffm.base.TFFMBaseModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, **init_params)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, X, y, sample_weight=None, pos_class_weight=None, n_epochs=None, show_progress=False)\n",
      "     |  \n",
      "     |  predict(self, X, pred_batch_size=None)\n",
      "     |      Predict using the FM model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {numpy.array, scipy.sparse.csr_matrix}, shape = (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |      pred_batch_size : int batch size for prediction (default None)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      predictions : array, shape = (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |  \n",
      "     |  predict_proba(self, X, pred_batch_size=None)\n",
      "     |      Probability estimates.\n",
      "     |      \n",
      "     |      The returned estimates for all 2 classes are ordered by the\n",
      "     |      label of classes.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, shape = [n_samples, n_features]\n",
      "     |      pred_batch_size : int batch size for prediction (default None)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      probs : array-like, shape = [n_samples, 2]\n",
      "     |          Returns the probability of the sample for each class in the model.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tffm.base.TFFMBaseModel:\n",
      "     |  \n",
      "     |  decision_function(self, X, pred_batch_size=None)\n",
      "     |  \n",
      "     |  destroy(self)\n",
      "     |      Terminates session and destroyes graph.\n",
      "     |  \n",
      "     |  init_basemodel(self, n_epochs=100, batch_size=-1, log_dir=None, session_config=None, verbose=0, seed=None, sample_weight=None, pos_class_weight=None, **core_arguments)\n",
      "     |  \n",
      "     |  initialize_session(self)\n",
      "     |      Start computational session on builded graph.\n",
      "     |      Initialize summary logger (if needed).\n",
      "     |  \n",
      "     |  load_state(self, path)\n",
      "     |  \n",
      "     |  save_state(self, path)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tffm.base.TFFMBaseModel:\n",
      "     |  \n",
      "     |  intercept\n",
      "     |      Export bias term from tf.Variable to float.\n",
      "     |  \n",
      "     |  weights\n",
      "     |      Export underlying weights from tf.Variables to np.arrays.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : boolean, optional\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : mapping of string to any\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as pipelines). The latter have parameters of the form\n",
      "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
      "     |      component of a nested object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class TFFMRegressor(tffm.base.TFFMBaseModel)\n",
      "     |  Factorization Machine (aka FM).\n",
      "     |  \n",
      "     |  This class implements L2-regularized arbitrary order FM model with MSE\n",
      "     |  loss and gradient-based optimization.\n",
      "     |  \n",
      "     |  Custom loss functions are not supported, mean squared error is always\n",
      "     |  used. Any loss function provided in parameters will be overwritten.\n",
      "     |  \n",
      "     |  See TFFMBaseModel and TFFMCore docs for details about parameters.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TFFMRegressor\n",
      "     |      tffm.base.TFFMBaseModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, **init_params)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, X, y, sample_weight=None, n_epochs=None, show_progress=False)\n",
      "     |  \n",
      "     |  predict(self, X, pred_batch_size=None)\n",
      "     |      Predict using the FM model\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {numpy.array, scipy.sparse.csr_matrix}, shape = (n_samples, n_features)\n",
      "     |          Samples.\n",
      "     |      pred_batch_size : int batch size for prediction (default None)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      predictions : array, shape = (n_samples,)\n",
      "     |          Returns predicted values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tffm.base.TFFMBaseModel:\n",
      "     |  \n",
      "     |  decision_function(self, X, pred_batch_size=None)\n",
      "     |  \n",
      "     |  destroy(self)\n",
      "     |      Terminates session and destroyes graph.\n",
      "     |  \n",
      "     |  init_basemodel(self, n_epochs=100, batch_size=-1, log_dir=None, session_config=None, verbose=0, seed=None, sample_weight=None, pos_class_weight=None, **core_arguments)\n",
      "     |  \n",
      "     |  initialize_session(self)\n",
      "     |      Start computational session on builded graph.\n",
      "     |      Initialize summary logger (if needed).\n",
      "     |  \n",
      "     |  load_state(self, path)\n",
      "     |  \n",
      "     |  save_state(self, path)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tffm.base.TFFMBaseModel:\n",
      "     |  \n",
      "     |  intercept\n",
      "     |      Export bias term from tf.Variable to float.\n",
      "     |  \n",
      "     |  weights\n",
      "     |      Export underlying weights from tf.Variables to np.arrays.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : boolean, optional\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : mapping of string to any\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as pipelines). The latter have parameters of the form\n",
      "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
      "     |      component of a nested object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "DATA\n",
      "    __all__ = ['TFFMClassifier', 'TFFMRegressor']\n",
      "\n",
      "FILE\n",
      "    c:\\programdata\\anaconda3\\lib\\site-packages\\tffm\\__init__.py\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "help(tffm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainFile = 'round1_ijcai_18_train_20180301.txt'\n",
    "testFile = 'round1_ijcai_18_test_a_20180301.txt'\n",
    "dataDir = '../../Data/advertisment/Raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTrain = pd.read_table(dataDir+trainFile,sep=' ')\n",
    "dfTest = pd.read_table(dataDir+testFile,sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance_id                    int64\n",
      "item_id                        int64\n",
      "item_category_list            object\n",
      "item_property_list            object\n",
      "item_brand_id                  int64\n",
      "item_city_id                   int64\n",
      "item_price_level               int64\n",
      "item_sales_level               int64\n",
      "item_collected_level           int64\n",
      "item_pv_level                  int64\n",
      "user_id                        int64\n",
      "user_gender_id                 int64\n",
      "user_age_level                 int64\n",
      "user_occupation_id             int64\n",
      "user_star_level                int64\n",
      "context_id                     int64\n",
      "context_timestamp              int64\n",
      "context_page_id                int64\n",
      "predict_category_property     object\n",
      "shop_id                        int64\n",
      "shop_review_num_level          int64\n",
      "shop_review_positive_rate    float64\n",
      "shop_star_level                int64\n",
      "shop_score_service           float64\n",
      "shop_score_delivery          float64\n",
      "shop_score_description       float64\n",
      "is_trade                       int64\n",
      "dtype: object\n",
      "(478138, 27)\n"
     ]
    }
   ],
   "source": [
    "print(dfTrain.dtypes)\n",
    "print(dfTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['item_brand_id', 'item_city_id', 'item_price_level', 'item_sales_level', 'item_collected_level', 'item_pv_level', 'user_gender_id', 'user_age_level', 'user_occupation_id', 'user_star_level', 'context_timestamp', 'context_page_id', 'shop_review_num_level', 'shop_review_positive_rate', 'shop_star_level', 'shop_score_service', 'shop_score_delivery', 'shop_score_description']\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "featInput = []\n",
    "keyList = ['instance_id','item_id','user_id','context_id','shop_id','is_trade']\n",
    "for var in dfTrain.columns:\n",
    "    if not var in keyList and dfTrain[var].dtypes != 'object':\n",
    "        featInput.append(var)\n",
    "print(featInput)\n",
    "print(len(featInput))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#0099ff size=5 face=\"黑体\">处理日期</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timestamp_datetime(value):\n",
    "    format = '%Y-%m-%d %H:%M:%S'\n",
    "    value = time.localtime(value)\n",
    "    dt = time.strftime(format, value)\n",
    "    return value.tm_hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTrain['context_timestamp_hour'] = dfTrain['context_timestamp'].map(timestamp_datetime)\n",
    "try: featInput.remove('context_timestamp')\n",
    "except: print('context_timestamp has been deleted')\n",
    "if not 'context_timestamp_hour' in featInput:\n",
    "    featInput.append('context_timestamp_hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=#0099ff size=5 face=\"黑体\">One Hot变形</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_brand_id\n",
      "item_price_level\n",
      "item_collected_level\n",
      "user_gender_id\n",
      "user_occupation_id\n",
      "context_page_id\n",
      "shop_star_level\n",
      "context_timestamp_hour\n"
     ]
    }
   ],
   "source": [
    "dummyInput = []\n",
    "for var in featInput:\n",
    "    if 'int' in str(dfTrain[var].dtypes):\n",
    "        print(var)\n",
    "        dfTrain[var].replace({-1:np.nan},inplace=True)\n",
    "        dfTmp = pd.get_dummies(dfTrain[var],var)\n",
    "        dfTrain = pd.concat([dfTrain,dfTmp],axis=1)\n",
    "        try:\n",
    "            featInput.remove(var)\n",
    "            dummyInput +=dfTmp.columns.tolist()\n",
    "        except:\n",
    "            print('Removed')\n",
    "featInput+=dummyInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['instance_id', 'item_id', 'item_category_list', 'item_property_list',\n",
      "       'item_brand_id', 'item_city_id', 'item_price_level', 'item_sales_level',\n",
      "       'item_collected_level', 'item_pv_level',\n",
      "       ...\n",
      "       'context_timestamp_hour_14', 'context_timestamp_hour_15',\n",
      "       'context_timestamp_hour_16', 'context_timestamp_hour_17',\n",
      "       'context_timestamp_hour_18', 'context_timestamp_hour_19',\n",
      "       'context_timestamp_hour_20', 'context_timestamp_hour_21',\n",
      "       'context_timestamp_hour_22', 'context_timestamp_hour_23'],\n",
      "      dtype='object', length=2187)\n",
      "(478138, 2187)\n"
     ]
    }
   ],
   "source": [
    "print(dfTrain.columns)\n",
    "print(dfTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=#0099ff size=5 face=\"黑体\">CV 创建模型输入</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for trainIndex,testIndex in cv.split(dfTrain[keyList]):\n",
    "    trainX,testX = dfTrain.loc[trainIndex,featInput],dfTrain.loc[testIndex,featInput]\n",
    "    trainY,testY = dfTrain.loc[trainIndex,'is_trade'],dfTrain.loc[testIndex,'is_trade']\n",
    "    \n",
    "    fm_dim = trainX.shape[1]\n",
    "    fm_initDev = .01\n",
    "    hashSalt = \"salty\"\n",
    "\n",
    "    alpha = .1\n",
    "    beta = 1.\n",
    "\n",
    "    alpha_fm = .01\n",
    "    beta_fm = 1.\n",
    "\n",
    "    p_D = 15\n",
    "    D = 2 ** p_D\n",
    "\n",
    "    L1 = 1.0\n",
    "    L2 = .1\n",
    "    L1_fm = 2.0\n",
    "    L2_fm = 3.0\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = tffm.TFFMClassifier(\n",
    "    order=6,\n",
    "    rank=10,\n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "    n_epochs=100,\n",
    "    batch_size=-1,\n",
    "    init_std=0.001,\n",
    "    input_type='dense'\n",
    ")\n",
    "model.fit(trainX.values, trainY.values, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_dim = trainX.shape[1]\n",
    "fm_initDev = .01\n",
    "hashSalt = \"salty\"\n",
    "\n",
    "alpha = .1\n",
    "beta = 1.\n",
    "\n",
    "alpha_fm = .01\n",
    "beta_fm = 1.\n",
    "\n",
    "p_D = 15\n",
    "D = 2 ** p_D\n",
    "\n",
    "L1 = 1.0\n",
    "L2 = .1\n",
    "L1_fm = 2.0\n",
    "L2_fm = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logLoss(p, y):\n",
    "    ''' \n",
    "    calculate the log loss cost\n",
    "    p: prediction [0, 1]\n",
    "    y: actual value {0, 1}\n",
    "    '''\n",
    "    p = max(min(p, 1. - 1e-15), 1e-15)\n",
    "    return - log(p) if y == 1. else -log(1. - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-7ed9d43bd43b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mtrainYTmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrainIndex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrainIndex\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m40000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainXTmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainYTmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mlearner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainXTmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainYTmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\02.Competition\\advertisment\\Code\\tools\\FM_FTRL_machine.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    116\u001b[0m         ''' predict the logit\n\u001b[0;32m    117\u001b[0m         '''\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m35.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m35.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\02.Competition\\advertisment\\Code\\tools\\FM_FTRL_machine.py\u001b[0m in \u001b[0;36mpredict_raw\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;31m# calculate the first order contribution.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[0msign\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1.\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;31m# get sign of z[i]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msign\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mL1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "learner = FM_FTRL_machine.FM_FTRL_machine(fm_dim, fm_initDev, L1, L2, L1_fm, L2_fm, D, alpha, beta, alpha_fm = alpha_fm, beta_fm = beta_fm)\n",
    "\n",
    "print(\"Start Training:\")\n",
    "n_epochs = 5\n",
    "for e in range(n_epochs):\n",
    "    \n",
    "    # if it is the first epoch, then don't use L1_fm or L2_fm\n",
    "    if e == 0:\n",
    "        learner.L1_fm = 0.\n",
    "        learner.L2_fm = 0.\n",
    "    else:\n",
    "        learner.L1_fm = L1_fm\n",
    "        learner.L2_fm = L2_fm\n",
    "    cvLoss = 0.\n",
    "    cvCount = 0.\n",
    "    progressiveLoss = 0.\n",
    "    progressiveCount = 0.\n",
    "    \n",
    "    for trainIndex in range(0,trainX.shape[0],40000):\n",
    "        trainXTmp = trainX.iloc[trainIndex:trainIndex+40000]\n",
    "        trainYTmp = trainY.iloc[trainIndex:trainIndex+40000]\n",
    "        \n",
    "        p = learner.predict(trainXTmp)\n",
    "        loss = logLoss(p, trainYTmp)\n",
    "        learner.update(trainXTmp, p, trainYTmp)\n",
    "\n",
    "        progressiveLoss += loss\n",
    "        progressiveCount += 1.\n",
    "    print('completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

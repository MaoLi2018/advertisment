{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fm_tool(object):\n",
    "    def __init__(self,epochs=5,learningRate=0.01,k=32):\n",
    "        self.epochs = epochs\n",
    "        self.learningRate = learningRate\n",
    "        self.k = k\n",
    "        \n",
    "        \n",
    "    def predict_raw(self,trainX):\n",
    "        result = (trainX.T*self.weight_first).sum(axis=0).reshape(trainX.shape[0],1) + self.weight_constant\n",
    "        for i in range(0,trainX.shape[1]-1):\n",
    "            for j in range(i+1,trainX.shape[1]):\n",
    "                result = result + np.dot(self.weight_second[i,:],self.weight_second[j,:])*(trainX[:,i]*trainX[:,j]).reshape(trainX.shape[0],1)\n",
    "        return result\n",
    "    \n",
    "    def predict(self,trainX):\n",
    "        return (1/(1+np.exp(-1*self.predict_raw(trainX))))\n",
    "        \n",
    "    def fit(self,trainX,trainy,valX,valy,k,verbose=False):\n",
    "        ###init the model\n",
    "        self.k = k\n",
    "        trainyTmp = trainy.reshape(trainy.shape[0],1)\n",
    "        self.weight_constant = 0\n",
    "        self.weight_first = np.random.randn(trainX.shape[1],1)\n",
    "        self.weight_second = np.random.randn(trainX.shape[1],self.k)\n",
    "        \n",
    "        '''if batchSize <= 0:\n",
    "            batchSize = trainXTmp.shape[0]'''\n",
    "        for n in range(self.epochs):\n",
    "            start_time = time.time()\n",
    "            #gradientBase = -1*trainyTmp*np.exp(-1*trainyTmp*self.predict_raw(trainXTmp))/(1+np.exp(-1*trainyTmp*self.predict_raw(trainXTmp)))\n",
    "            gradientBase = -1*trainyTmp + self.predict(trainX)\n",
    "            #print(gradientBase)\n",
    "\n",
    "            self.learningRate = 0.9*self.learningRate\n",
    "            for i in range(trainX.shape[0]):\n",
    "                recordTmp = trainX[i].reshape(trainX.shape[1],1)\n",
    "                gradientBaseTmp = gradientBase[i].reshape(gradientBase.shape[1],1)\n",
    "                gradientInteraction = (self.weight_second*recordTmp).sum(axis=0)\n",
    "                self.weight_constant = self.weight_constant - self.learningRate*gradientBaseTmp\n",
    "                self.weight_first = self.weight_first - self.learningRate*gradientBaseTmp*recordTmp   \n",
    "                self.weight_second = self.weight_second - self.learningRate*gradientBaseTmp*(np.outer(recordTmp,gradientInteraction)-np.power(recordTmp,2)*self.weight_second)\n",
    "            if verbose:\n",
    "                print('epoch--%d in %.2f s'%(n,time.time()-start_time))\n",
    "                print('Train Set accuracy: %.4f'%self.accuracy(trainX,trainy))\n",
    "                try: print('Validation Set accuracy: %.4f'%self.accuracy(valX,valy))\n",
    "                except: continue\n",
    "            \n",
    "    def accuracy(self,trainX,trainy):\n",
    "        return -1*(np.log(1- trainy.reshape(trainy.shape[0],1)-self.predict(trainX)+2*trainy.reshape(trainy.shape[0],1)*self.predict(trainX)).mean())\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch--0 in 0.00 s\n",
      "Train Set accuracy: inf\n",
      "epoch--1 in 0.00 s\n",
      "Train Set accuracy: inf\n",
      "epoch--2 in 0.00 s\n",
      "Train Set accuracy: 1.4282\n",
      "epoch--3 in 0.00 s\n",
      "Train Set accuracy: 0.5876\n",
      "epoch--4 in 0.00 s\n",
      "Train Set accuracy: 0.2818\n",
      "epoch--5 in 0.00 s\n",
      "Train Set accuracy: 0.0891\n",
      "epoch--6 in 0.00 s\n",
      "Train Set accuracy: 0.0514\n",
      "epoch--7 in 0.00 s\n",
      "Train Set accuracy: 0.0387\n",
      "epoch--8 in 0.00 s\n",
      "Train Set accuracy: 0.0319\n",
      "epoch--9 in 0.00 s\n",
      "Train Set accuracy: 0.0277\n",
      "epoch--10 in 0.00 s\n",
      "Train Set accuracy: 0.0248\n",
      "epoch--11 in 0.00 s\n",
      "Train Set accuracy: 0.0227\n",
      "epoch--12 in 0.00 s\n",
      "Train Set accuracy: 0.0211\n",
      "epoch--13 in 0.00 s\n",
      "Train Set accuracy: 0.0199\n",
      "epoch--14 in 0.00 s\n",
      "Train Set accuracy: 0.0189\n",
      "epoch--15 in 0.00 s\n",
      "Train Set accuracy: 0.0181\n",
      "epoch--16 in 0.00 s\n",
      "Train Set accuracy: 0.0175\n",
      "epoch--17 in 0.00 s\n",
      "Train Set accuracy: 0.0169\n",
      "epoch--18 in 0.00 s\n",
      "Train Set accuracy: 0.0165\n",
      "epoch--19 in 0.00 s\n",
      "Train Set accuracy: 0.0161\n",
      "epoch--20 in 0.00 s\n",
      "Train Set accuracy: 0.0157\n",
      "epoch--21 in 0.00 s\n",
      "Train Set accuracy: 0.0154\n",
      "epoch--22 in 0.00 s\n",
      "Train Set accuracy: 0.0152\n",
      "epoch--23 in 0.00 s\n",
      "Train Set accuracy: 0.0150\n",
      "epoch--24 in 0.00 s\n",
      "Train Set accuracy: 0.0148\n",
      "epoch--25 in 0.00 s\n",
      "Train Set accuracy: 0.0146\n",
      "epoch--26 in 0.00 s\n",
      "Train Set accuracy: 0.0145\n",
      "epoch--27 in 0.00 s\n",
      "Train Set accuracy: 0.0143\n",
      "epoch--28 in 0.00 s\n",
      "Train Set accuracy: 0.0142\n",
      "epoch--29 in 0.00 s\n",
      "Train Set accuracy: 0.0141\n",
      "epoch--30 in 0.00 s\n",
      "Train Set accuracy: 0.0140\n",
      "epoch--31 in 0.00 s\n",
      "Train Set accuracy: 0.0139\n",
      "epoch--32 in 0.00 s\n",
      "Train Set accuracy: 0.0139\n",
      "epoch--33 in 0.00 s\n",
      "Train Set accuracy: 0.0138\n",
      "epoch--34 in 0.00 s\n",
      "Train Set accuracy: 0.0137\n",
      "epoch--35 in 0.00 s\n",
      "Train Set accuracy: 0.0137\n",
      "epoch--36 in 0.00 s\n",
      "Train Set accuracy: 0.0136\n",
      "epoch--37 in 0.00 s\n",
      "Train Set accuracy: 0.0136\n",
      "epoch--38 in 0.00 s\n",
      "Train Set accuracy: 0.0136\n",
      "epoch--39 in 0.00 s\n",
      "Train Set accuracy: 0.0135\n",
      "epoch--40 in 0.00 s\n",
      "Train Set accuracy: 0.0135\n",
      "epoch--41 in 0.00 s\n",
      "Train Set accuracy: 0.0135\n",
      "epoch--42 in 0.00 s\n",
      "Train Set accuracy: 0.0135\n",
      "epoch--43 in 0.00 s\n",
      "Train Set accuracy: 0.0134\n",
      "epoch--44 in 0.00 s\n",
      "Train Set accuracy: 0.0134\n",
      "epoch--45 in 0.00 s\n",
      "Train Set accuracy: 0.0134\n",
      "epoch--46 in 0.00 s\n",
      "Train Set accuracy: 0.0134\n",
      "epoch--47 in 0.00 s\n",
      "Train Set accuracy: 0.0134\n",
      "epoch--48 in 0.00 s\n",
      "Train Set accuracy: 0.0134\n",
      "epoch--49 in 0.00 s\n",
      "Train Set accuracy: 0.0134\n",
      "epoch--50 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--51 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--52 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--53 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--54 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--55 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--56 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--57 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--58 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--59 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--60 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--61 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--62 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--63 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--64 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--65 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--66 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--67 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--68 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--69 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--70 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--71 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--72 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--73 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--74 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--75 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--76 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--77 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--78 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--79 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--80 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--81 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--82 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--83 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--84 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--85 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--86 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--87 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--88 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--89 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--90 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--91 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--92 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--93 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--94 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--95 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--96 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--97 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--98 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n",
      "epoch--99 in 0.00 s\n",
      "Train Set accuracy: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo Mao\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "fm =fm_tool(learningRate=0.01,epochs=100)\n",
    "fm.fit(trainX=np.random.randn(200).reshape(20,10),trainy=np.array([0]*10+[1]*10),valX=0,valy=0,k=32,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.11841638e-01],\n",
       "       [  1.00000000e+00],\n",
       "       [  1.00000000e+00],\n",
       "       [  4.36343151e-12],\n",
       "       [  1.04558272e-19],\n",
       "       [  9.75006458e-16],\n",
       "       [  9.99880981e-01],\n",
       "       [  9.99999927e-01],\n",
       "       [  9.99999952e-01],\n",
       "       [  9.62003761e-39],\n",
       "       [  1.00000000e+00],\n",
       "       [  8.04848732e-02],\n",
       "       [  3.97952364e-01],\n",
       "       [  3.21854296e-01],\n",
       "       [  4.01801836e-45],\n",
       "       [  3.41292145e-07],\n",
       "       [  9.99999180e-01],\n",
       "       [  2.42034623e-06],\n",
       "       [  9.99999588e-01],\n",
       "       [  9.99993166e-01]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm.predict(np.random.randn(200).reshape(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1]*10+[0]*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  91.95127977]\n",
      " [ 296.22889855]\n",
      " [  33.18511209]\n",
      " [ -21.74464321]\n",
      " [  57.17284271]\n",
      " [  -4.59740915]\n",
      " [-265.79284337]\n",
      " [ -84.24525074]\n",
      " [  59.35325684]\n",
      " [-398.7980208 ]\n",
      " [ 140.93299238]\n",
      " [-614.58911937]\n",
      " [-125.69375053]\n",
      " [  11.64264124]\n",
      " [ 149.53743157]\n",
      " [  78.86551705]\n",
      " [  -3.57014774]\n",
      " [  -6.37859204]\n",
      " [  53.86491008]\n",
      " [  93.90635655]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+000],\n",
       "       [  1.00000000e+000],\n",
       "       [  1.00000000e+000],\n",
       "       [  3.60098610e-010],\n",
       "       [  1.00000000e+000],\n",
       "       [  9.97736134e-003],\n",
       "       [  3.69517315e-116],\n",
       "       [  2.58673820e-037],\n",
       "       [  1.00000000e+000],\n",
       "       [  6.37118436e-174],\n",
       "       [  1.00000000e+000],\n",
       "       [  1.22274760e-267],\n",
       "       [  2.58165220e-055],\n",
       "       [  9.99991217e-001],\n",
       "       [  1.00000000e+000],\n",
       "       [  1.00000000e+000],\n",
       "       [  2.73808761e-002],\n",
       "       [  1.69463463e-003],\n",
       "       [  1.00000000e+000],\n",
       "       [  1.00000000e+000]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm.predict(np.random.randn(200).reshape(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm.recordTmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm.gradientBase[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gradientInteraction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-9ae022a21c27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvaly\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-a2e395d6eefe>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, trainX, trainy, valX, valy, k)\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradientInteraction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_second\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mrecordTmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_first\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_first\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearningRate\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgradientBaseTmp\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mrecordTmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_second\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_second\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearningRate\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgradientBaseTmp\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecordTmp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgradientInteraction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecordTmp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_second\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gradientInteraction' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9],\n",
       "       [ 10,  11,  12,  13,  14,  15,  16,  17,  18,  19],\n",
       "       [ 20,  21,  22,  23,  24,  25,  26,  27,  28,  29],\n",
       "       [ 30,  31,  32,  33,  34,  35,  36,  37,  38,  39],\n",
       "       [ 40,  41,  42,  43,  44,  45,  46,  47,  48,  49],\n",
       "       [ 50,  51,  52,  53,  54,  55,  56,  57,  58,  59],\n",
       "       [ 60,  61,  62,  63,  64,  65,  66,  67,  68,  69],\n",
       "       [ 70,  71,  72,  73,  74,  75,  76,  77,  78,  79],\n",
       "       [ 80,  81,  82,  83,  84,  85,  86,  87,  88,  89],\n",
       "       [ 90,  91,  92,  93,  94,  95,  96,  97,  98,  99],\n",
       "       [100, 101, 102, 103, 104, 105, 106, 107, 108, 109],\n",
       "       [110, 111, 112, 113, 114, 115, 116, 117, 118, 119],\n",
       "       [120, 121, 122, 123, 124, 125, 126, 127, 128, 129],\n",
       "       [130, 131, 132, 133, 134, 135, 136, 137, 138, 139],\n",
       "       [140, 141, 142, 143, 144, 145, 146, 147, 148, 149],\n",
       "       [150, 151, 152, 153, 154, 155, 156, 157, 158, 159],\n",
       "       [160, 161, 162, 163, 164, 165, 166, 167, 168, 169],\n",
       "       [170, 171, 172, 173, 174, 175, 176, 177, 178, 179],\n",
       "       [180, 181, 182, 183, 184, 185, 186, 187, 188, 189],\n",
       "       [190, 191, 192, 193, 194, 195, 196, 197, 198, 199]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [6],\n",
       "       [7],\n",
       "       [8],\n",
       "       [9]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.arange(200).reshape(20,10)\n",
    "b = np.arange(10).reshape(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-75-933a8ff5327d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-75-933a8ff5327d>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    (a.T*b).sum(axis=0).reshape(,1)\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "(a.T*b).sum(axis=0).reshape(,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].reshape(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.75349653, -0.51598412],\n",
       "       [-0.86320491, -0.05595622],\n",
       "       [ 0.00452192,  0.94724225]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randn(3,2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1],\n",
       "       [ 4,  6],\n",
       "       [12, 15]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a*b)+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7405a507deb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mffm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ffm-1.0-py3.6-win-amd64.egg\\ffm\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mffm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFFMData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFFM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mread_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpd2ffm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFFMFormatPandas\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_libffm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_libffm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ffm-1.0-py3.6-win-amd64.egg\\ffm\\ffm.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mlibffm_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'libffm.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mlib_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlibffm_file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "''' Based on Tinrtgu's FTRL code: http://www.kaggle.com/c/avazu-ctr-prediction/forums/t/10927/beat-the-benchmark-with-less-than-1mb-of-memory\n",
    "'''\n",
    "\n",
    "from csv import DictReader\n",
    "from math import exp, copysign, log, sqrt\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "class FM_FTRL_machine(object):\n",
    "    \n",
    "    def __init__(self, fm_dim, fm_initDev, L1, L2, L1_fm, L2_fm, D, alpha, beta, alpha_fm = .1, beta_fm = 1.0, dropoutRate = 1.0):\n",
    "        ''' initialize the factorization machine.'''\n",
    "        \n",
    "        self.alpha = alpha              # learning rate parameter alpha\n",
    "        self.beta = beta                # learning rate parameter beta\n",
    "        self.L1 = L1                    # L1 regularizer for first order terms\n",
    "        self.L2 = L2                    # L2 regularizer for first order terms\n",
    "        self.alpha_fm = alpha_fm        # learning rate parameter alpha for factorization machine\n",
    "        self.beta_fm = beta_fm          # learning rate parameter beta for factorization machine\n",
    "        self.L1_fm = L1_fm              # L1 regularizer for factorization machine weights. Only use L1 after one epoch of training, because small initializations are needed for gradient.\n",
    "        self.L2_fm = L2_fm              # L2 regularizer for factorization machine weights.\n",
    "        self.fm_dim = fm_dim            # dimension of factorization.\n",
    "        self.fm_initDev = fm_initDev    # standard deviation for random intitialization of factorization weights.\n",
    "        self.dropoutRate = dropoutRate  # dropout rate (which is actually the inclusion rate), i.e. dropoutRate = .8 indicates a probability of .2 of dropping out a feature.\n",
    "        \n",
    "        self.D = D\n",
    "        \n",
    "        # model\n",
    "        # n: squared sum of past gradients\n",
    "        # z: weights\n",
    "        # w: lazy weights\n",
    "        \n",
    "        # let index 0 be bias term to avoid collisions.\n",
    "        self.n = [0.] * (D + 1) \n",
    "        self.z = [0.] * (D + 1)\n",
    "        self.w = [0.] * (D + 1)\n",
    "        \n",
    "        self.n_fm = {}\n",
    "        self.z_fm = {}\n",
    "        self.w_fm = {}\n",
    "    \n",
    "        \n",
    "    def init_fm(self, i):\n",
    "        ''' initialize the factorization weight vector for variable i.\n",
    "        '''\n",
    "        if i not in self.n_fm:\n",
    "            self.n_fm[i] = [0.] * self.fm_dim\n",
    "            self.w_fm[i] = [0.] * self.fm_dim\n",
    "            self.z_fm[i] = [0.] * self.fm_dim\n",
    "            \n",
    "            for k in range(self.fm_dim): \n",
    "                self.z_fm[i][k] = random.gauss(0., self.fm_initDev)\n",
    "    \n",
    "    def predict_raw(self, x):\n",
    "        ''' predict the raw score prior to logit transformation.\n",
    "        '''\n",
    "        alpha = self.alpha\n",
    "        beta = self.beta\n",
    "        L1 = self.L1\n",
    "        L2 = self.L2\n",
    "        alpha_fm = self.alpha_fm\n",
    "        beta_fm = self.beta_fm\n",
    "        L1_fm = self.L1_fm\n",
    "        L2_fm = self.L2_fm\n",
    "        \n",
    "        # first order weights model\n",
    "        n = self.n\n",
    "        z = self.z\n",
    "        w = self.w\n",
    "        \n",
    "        # FM interaction model\n",
    "        n_fm = self.n_fm\n",
    "        z_fm = self.z_fm\n",
    "        w_fm = self.w_fm\n",
    "        \n",
    "        raw_y = 0.\n",
    "        \n",
    "        # calculate the bias contribution\n",
    "        for i in [0]:\n",
    "            # no regularization for bias\n",
    "            w[i] = (- z[i]) / ((beta + sqrt(n[i])) / alpha)\n",
    "            \n",
    "            raw_y += w[i]\n",
    "        \n",
    "        # calculate the first order contribution.\n",
    "        for i in x:\n",
    "            sign = -1. if z[i] < 0. else 1. # get sign of z[i]\n",
    "            \n",
    "            if sign * z[i] <= L1:\n",
    "                w[i] = 0.\n",
    "            else:\n",
    "                w[i] = (sign * L1 - z[i]) / ((beta + sqrt(n[i])) / alpha + L2)\n",
    "            \n",
    "            raw_y += w[i]\n",
    "        \n",
    "        len_x = len(x)\n",
    "        # calculate factorization machine contribution.\n",
    "        for i in x:\n",
    "            self.init_fm(i)\n",
    "            for k in range(self.fm_dim):\n",
    "                sign = -1. if z_fm[i][k] < 0. else 1.   # get the sign of z_fm[i][k]\n",
    "                \n",
    "                if sign * z_fm[i][k] <= L1_fm:\n",
    "                    w_fm[i][k] = 0.\n",
    "                else:\n",
    "                    w_fm[i][k] = (sign * L1_fm - z_fm[i][k]) / ((beta_fm + sqrt(n_fm[i][k])) / alpha_fm + L2_fm)\n",
    "        \n",
    "        for i in range(len_x):\n",
    "            for j in range(i + 1, len_x):\n",
    "                for k in range(self.fm_dim):\n",
    "                    raw_y += w_fm[x[i]][k] * w_fm[x[j]][k]\n",
    "        \n",
    "        return raw_y\n",
    "    \n",
    "    def predict(self, x):\n",
    "        ''' predict the logit\n",
    "        '''\n",
    "        return 1. / (1. + exp(- max(min(self.predict_raw(x), 35.), -35.)))\n",
    "    \n",
    "    def dropout(self, x):\n",
    "        ''' dropout variables in list x\n",
    "        '''\n",
    "        for i, var in enumerate(x):\n",
    "            if random.random() > self.dropoutRate:\n",
    "                del x[i]\n",
    "    \n",
    "    def dropoutThenPredict(self, x):\n",
    "        ''' first dropout some variables and then predict the logit using the dropped out data.\n",
    "        '''\n",
    "        self.dropout(x)\n",
    "        return self.predict(x)\n",
    "    \n",
    "    def predictWithDroppedOutModel(self, x):\n",
    "        ''' predict using all data, using a model trained with dropout.\n",
    "        '''\n",
    "        return 1. / (1. + exp(- max(min(self.predict_raw(x) * self.dropoutRate, 35.), -35.)))\n",
    "    \n",
    "    def update(self, x, p, y):\n",
    "        ''' Update the parameters using FTRL (Follow the Regularized Leader)\n",
    "        '''\n",
    "        alpha = self.alpha\n",
    "        alpha_fm = self.alpha_fm\n",
    "        \n",
    "        # model\n",
    "        n = self.n\n",
    "        z = self.z\n",
    "        w = self.w\n",
    "        \n",
    "        # FM model\n",
    "        n_fm = self.n_fm\n",
    "        z_fm = self.z_fm\n",
    "        w_fm = self.w_fm\n",
    "        \n",
    "        # cost gradient with respect to raw prediction.\n",
    "        g = p - y\n",
    "        \n",
    "        fm_sum = {}      # sums for calculating gradients for FM.\n",
    "        len_x = len(x)\n",
    "        \n",
    "        for i in x + [0]:\n",
    "            # update the first order weights.\n",
    "            sigma = (sqrt(n[i] + g * g) - sqrt(n[i])) / alpha\n",
    "            z[i] += g - sigma * w[i]\n",
    "            n[i] += g * g\n",
    "            \n",
    "            # initialize the sum of the FM interaction weights.\n",
    "            fm_sum[i] = [0.] * self.fm_dim\n",
    "        \n",
    "        # sum the gradients for FM interaction weights.\n",
    "        for i in range(len_x):\n",
    "            for j in range(len_x):\n",
    "                if i != j:\n",
    "                    for k in range(self.fm_dim):\n",
    "                        fm_sum[x[i]][k] += w_fm[x[j]][k]\n",
    "        \n",
    "        for i in x:\n",
    "            for k in range(self.fm_dim):\n",
    "                g_fm = g * fm_sum[i][k]\n",
    "                sigma = (sqrt(n_fm[i][k] + g_fm * g_fm) - sqrt(n_fm[i][k])) / alpha_fm\n",
    "                z_fm[i][k] += g_fm - sigma * w_fm[i][k]\n",
    "                n_fm[i][k] += g_fm * g_fm\n",
    "    \n",
    "    def write_w(self, filePath):\n",
    "        ''' write out the first order weights w to a file.\n",
    "        '''\n",
    "        with open(filePath, \"w\") as f_out:\n",
    "            for i, w in enumerate(self.w):\n",
    "                f_out.write(\"%i,%f\\n\" % (i, w))\n",
    "    \n",
    "    def write_w_fm(self, filePath):\n",
    "        ''' write out the factorization machine weights to a file.\n",
    "        '''\n",
    "        with open(filePath, \"w\") as f_out:\n",
    "            for k, w_fm in self.w_fm.iteritems():\n",
    "                f_out.write(\"%i,%s\\n\" % (k, \",\".join([str(w) for w in w_fm])))\n",
    "\n",
    "\n",
    "def logLoss(p, y):\n",
    "    ''' \n",
    "    calculate the log loss cost\n",
    "    p: prediction [0, 1]\n",
    "    y: actual value {0, 1}\n",
    "    '''\n",
    "    p = max(min(p, 1. - 1e-15), 1e-15)\n",
    "    return - log(p) if y == 1. else -log(1. - p)\n",
    "\n",
    "def data(filePath, hashSize, hashSalt):\n",
    "    ''' generator for data using hash trick\n",
    "    \n",
    "    INPUT:\n",
    "        filePath\n",
    "        hashSize\n",
    "        hashSalt: String with which to salt the hash function\n",
    "    '''\n",
    "    \n",
    "    for t, row in enumerate(DictReader(open(filePath))):\n",
    "        ID = row['id']\n",
    "        del row['id']\n",
    "        \n",
    "        y = 0.\n",
    "        if 'click' in row:\n",
    "            if row['click'] == '1':\n",
    "                y = 1.\n",
    "            del row['click']\n",
    "        \n",
    "        date = int(row['hour'][4:6])\n",
    "        \n",
    "        row['hour'] = row['hour'][6:]\n",
    "        \n",
    "        x = []\n",
    "        \n",
    "        for key in row:\n",
    "            value = row[key]\n",
    "            \n",
    "            index = abs(hash(hashSalt + key + '_' + value)) % hashSize + 1      # 1 is added to hash index because I want 0 to indicate the bias term.\n",
    "            x.append(index)\n",
    "        \n",
    "        yield t, date, ID, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
